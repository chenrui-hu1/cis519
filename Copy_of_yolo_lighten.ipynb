{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3x_M6aXcOGnO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://gitlab.com/irafm-ai/poly-yolo.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "utyhF1BTNVoz",
        "outputId": "b22dd832-c9cf-4c4f-f503-204f647d2b30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'poly-yolo' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/poly-yolo/poly_yolo"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HMW6tV8Nk5M",
        "outputId": "9bcbac51-545e-43ad-8368-34662e16f6de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/poly-yolo/poly_yolo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 1.x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btRVHiiSO-t4",
        "outputId": "0c454ecf-4c48-4105-fa97-76136fc00ca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow 1.x selected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zs7vUDw15hX0",
        "outputId": "f5318c42-f9d8-421d-bf37-f68502384c4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "import poly_yolo_lite as yolo #or \"import poly_yolo_lite as yolo\" for the lite version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install 'h5py==2.10.0' --force-reinstall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "SctZzzdbQeNr",
        "outputId": "47972ebe-ebd2-443a-a09e-368027cfa39d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 29.4 MB/s \n",
            "\u001b[?25hCollecting six\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting numpy>=1.7\n",
            "  Downloading numpy-1.21.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.7 MB 63.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: six, numpy, h5py\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.21.6\n",
            "    Uninstalling numpy-1.21.6:\n",
            "      Successfully uninstalled numpy-1.21.6\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.8.0 requires tf-estimator-nightly==2.8.0.dev2021122109, which is not installed.\n",
            "google-colab 1.0.0 requires six~=1.15.0, but you have six 1.16.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed h5py-2.10.0 numpy-1.21.6 six-1.16.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy",
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "keras.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jMwILmSc5fSk",
        "outputId": "f8d59ac8-4bf4-4a1d-b7e6-1edb9c1e2abb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.3.1'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "UNHZNPP95hX3",
        "outputId": "f1f46e07-d6d5-4782-e314-a68c0b45a740",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "/content/poly-yolo/poly_yolo/models/poly_yolo_lite.h5 model, anchors, and classes loaded.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        }
      ],
      "source": [
        "#load pretrained model\n",
        "#if you want to detect more objects, lower the score and vice versa\n",
        "trained_model = yolo.YOLO(model_path='/content/poly-yolo/poly_yolo/models/poly_yolo_lite.h5', iou=0.5, score=0.3)\n",
        "#trained_model = yolo.YOLO(model_path='/content/poly-yolo/poly_yolo/models/ep003-loss109.321-val_loss52.341.h5', anchor_path=\"/content/poly-yolo/poly_yolo/yolo_anchors.txt\", \n",
        "                          #iou=0.5, score=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGdeBzYf5hX4"
      },
      "outputs": [],
      "source": [
        "#helper function\n",
        "def translate_color(cls):\n",
        "    if cls == 0: return (230, 25, 75)\n",
        "    if cls == 1: return (60, 180, 75)\n",
        "    if cls == 2: return (255, 225, 25)\n",
        "    if cls == 3: return (0, 130, 200)\n",
        "    if cls == 4: return (245, 130, 48)\n",
        "    if cls == 5: return (145, 30, 180)\n",
        "    if cls == 7: return (70, 240, 240)\n",
        "    if cls == 8: return (240, 50, 230)\n",
        "    if cls == 9: return (210, 245, 60)\n",
        "    if cls == 10: return (250, 190, 190)\n",
        "    if cls == 11: return (0, 128, 128)\n",
        "    if cls == 12: return (230, 190, 255)\n",
        "    if cls == 13: return (170, 110, 40)\n",
        "    if cls == 14: return (255, 250, 200)\n",
        "    if cls == 15: return (128, 0, 128)\n",
        "    if cls == 16: return (170, 255, 195)\n",
        "    if cls == 17: return (128, 128, 0)\n",
        "    if cls == 18: return (255, 215, 180)\n",
        "    if cls == 19: return (80, 80, 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "N62WNlEZ5hX5",
        "outputId": "454b84de-2ffe-4d01-b853-95b68eeee07c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 2882, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-8-34cfe7406adf>\", line 20, in <module>\n",
            "    box, scores, classes, polygons = trained_model.detect_image(img)\n",
            "  File \"/content/poly-yolo/poly_yolo/poly_yolo_lite.py\", line 898, in detect_image\n",
            "    K.learning_phase(): 0\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 956, in run\n",
            "    run_metadata_ptr)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1180, in _run\n",
            "    feed_dict_tensor, options, run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n",
            "    run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n",
            "    return fn(*args)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n",
            "    target_list, run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n",
            "    run_metadata)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\", line 1823, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/dask/delayed.py\", line 8, in <module>\n",
            "    from cytoolz import curry, concat, unique, merge\n",
            "ModuleNotFoundError: No module named 'cytoolz'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 1132, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/IPython/core/ultratb.py\", line 358, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1502, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1460, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 696, in getsourcefile\n",
            "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 733, in getmodule\n",
            "    if ismodule(module) and hasattr(module, '__file__'):\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow/__init__.py\", line 50, in __getattr__\n",
            "    module = self._load()\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow/__init__.py\", line 44, in _load\n",
            "    module = _importlib.import_module(self.__name__)\n",
            "  File \"/usr/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"<frozen importlib._bootstrap>\", line 1006, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/__init__.py\", line 47, in <module>\n",
            "    from tensorflow.contrib import distributions\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/distributions/__init__.py\", line 29, in <module>\n",
            "    from tensorflow.contrib.distributions.python.ops import bijectors\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/distributions/__init__.py\", line 44, in <module>\n",
            "    from tensorflow.contrib.distributions.python.ops.estimator import *\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/distributions/python/ops/estimator.py\", line 21, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn.estimators.head import _compute_weighted_loss\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/__init__.py\", line 93, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn import *\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/__init__.py\", line 28, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn import *\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/__init__.py\", line 30, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn import estimators\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/__init__.py\", line 302, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn.estimators.dnn import DNNClassifier\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/dnn.py\", line 34, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn.estimators import dnn_linear_combined\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/dnn_linear_combined.py\", line 36, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn.estimators import estimator\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/estimators/estimator.py\", line 52, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn.learn_io import data_feeder\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/learn_io/__init__.py\", line 26, in <module>\n",
            "    from tensorflow.contrib.learn.python.learn.learn_io.dask_io import extract_dask_data\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/contrib/learn/python/learn/learn_io/dask_io.py\", line 33, in <module>\n",
            "    import dask.dataframe as dd\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/dask/__init__.py\", line 6, in <module>\n",
            "    from .delayed import delayed\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/dask/delayed.py\", line 10, in <module>\n",
            "    from toolz import curry, concat, unique, merge\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/toolz/__init__.py\", line 20, in <module>\n",
            "    from . import curried, sandbox\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/toolz/curried/__init__.py\", line 27, in <module>\n",
            "    from . import operator\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/toolz/curried/operator.py\", line 15, in <module>\n",
            "    for name, f in vars(operator).items() if callable(f)},\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/toolz/curried/operator.py\", line 15, in <dictcomp>\n",
            "    for name, f in vars(operator).items() if callable(f)},\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/toolz/curried/operator.py\", line 9, in should_curry\n",
            "    num = num_required_args(f)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/toolz/functoolz.py\", line 867, in num_required_args\n",
            "    func)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/toolz/functoolz.py\", line 827, in _check_sigspec\n",
            "    sigspec = inspect.signature(func)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 3083, in signature\n",
            "    return Signature.from_callable(obj, follow_wrapped=follow_wrapped)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 2833, in from_callable\n",
            "    follow_wrapper_chains=follow_wrapped)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 2288, in _signature_from_callable\n",
            "    skip_bound_arg=skip_bound_arg)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 2114, in _signature_from_builtin\n",
            "    return _signature_fromstr(cls, func, s, skip_bound_arg)\n",
            "  File \"/usr/lib/python3.7/inspect.py\", line 1993, in _signature_fromstr\n",
            "    sys_module_dict = sys.modules.copy()\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
          ]
        }
      ],
      "source": [
        "dir_imgs_name = '/content/poly-yolo/simulator_dataset/imgs'  #path_where_are_images_to_clasification\n",
        "!mkdir /content/poly-yolo/poly_yolo_predict\n",
        "out_path       = '/content/poly-yolo/poly_yolo_predict/' #path, where the images will be saved. The path must exist\n",
        "list_of_imgs = [root+\"/\"+name for root, dirs, files in os.walk(dir_imgs_name) for name in files]   \n",
        "list_of_imgs.sort()\n",
        "\n",
        "#browse all images\n",
        "total_boxes = 0\n",
        "imgs        = 0\n",
        "for im in range (0, len(list_of_imgs)):\n",
        "    imgs    += 1\n",
        "    img     = cv2.imread(list_of_imgs[im])\n",
        "    overlay = img.copy()\n",
        "    boxes   = []\n",
        "    scores  = []\n",
        "    classes = []\n",
        "    \n",
        "    #realize prediciction using poly-yolo\n",
        "    startx = time.time()\n",
        "    box, scores, classes, polygons = trained_model.detect_image(img)\n",
        "    print('Prediction speed: ', 1.0/(time.time() - startx), 'fps')\n",
        "    \n",
        "    \n",
        "    #example, hw to reshape reshape y1,x1,y2,x2 into x1,y1,x2,y2\n",
        "    for k in range (0, len(box)):\n",
        "        boxes.append((box[k][1], box[k][0], box[k][3], box[k][2]))\n",
        "        cv2.rectangle(img, (box[k][1],box[k][0]), (box[k][3],box[k][2]), translate_color(classes[k]), 3, 1)\n",
        "    total_boxes += len(boxes)\n",
        "    \n",
        "    #browse all boxes\n",
        "    for b in range(0, len(boxes)):\n",
        "        f              = translate_color(classes[b])    \n",
        "        points_to_draw = []\n",
        "        offset         = len(polygons[b])//3\n",
        "        \n",
        "        #filter bounding polygon vertices\n",
        "        for dst in range(0, len(polygons[b])//3):\n",
        "            if polygons[b][dst+offset*2] > 0.3: \n",
        "                points_to_draw.append([int(polygons[b][dst]), int(polygons[b][dst+offset])])\n",
        "        \n",
        "        points_to_draw = np.asarray(points_to_draw)\n",
        "        points_to_draw = points_to_draw.astype(np.int32)\n",
        "        if points_to_draw.shape[0]>0:\n",
        "            cv2.polylines(img, [points_to_draw],True,f, thickness=2)\n",
        "            cv2.fillPoly(overlay, [points_to_draw], f)\n",
        "    img = cv2.addWeighted(overlay, 0.4, img, 1 - 0.4, 0)\n",
        "    cv2.imwrite(out_path+str(imgs)+'.jpg', img)\n",
        "    \n",
        "print('total boxes: ', total_boxes)\n",
        "print('imgs: ', imgs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm /content/poly-yolo/poly_yolo/img_r_*.png"
      ],
      "metadata": {
        "id": "c59MCPsC83VF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bfcaf29-e723-4f7e-9d65-7d8aff997b81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/poly-yolo/poly_yolo/img_r_*.png': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kmeans\n",
        "yolo_kmeans = kmeans.YOLO_Kmeans(9, \"/content/poly-yolo/simulator_dataset/simulator-train.txt\")\n",
        "yolo_kmeans.txt2clusters()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQEQElzd_X8_",
        "outputId": "e7b0c6e6-52ed-4781-f041-9e13317a6aff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "K anchors:\n",
            " [[-9223372036854775808 -9223372036854775808]\n",
            " [                   1                    2]\n",
            " [                   2                    5]\n",
            " [                   3                    1]\n",
            " [                   4                    8]\n",
            " [                  10                    2]\n",
            " [                  11                   12]\n",
            " [                  13                    6]\n",
            " [                  35                   22]]\n",
            "Accuracy: 62.79%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/fromnumeric.py:3441: RuntimeWarning: Mean of empty slice.\n",
            "  out=out, **kwargs)\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:182: RuntimeWarning: invalid value encountered in true_divide\n",
            "  ret, rcount, out=ret, casting='unsafe', subok=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = yolo.YOLO(model_path=\"/content/poly-yolo/poly_yolo/models/poly_yolo_lite.h5\", \n",
        "                         anchor_path=\"/content/poly-yolo/poly_yolo/yolo_anchors.txt\", iou=0.5, score=0.3)\n"
      ],
      "metadata": {
        "id": "8mhsvZXedZw9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "199d840c-dbb0-4914-f986-7970995e8018"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/poly-yolo/poly_yolo/models/poly_yolo_lite.h5 model, anchors, and classes loaded.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dir_imgs_name = '/content/poly-yolo/simulator_dataset/imgs'  #path_where_are_images_to_clasification\n",
        "!mkdir /content/poly-yolo/poly_yolo_predict\n",
        "out_path       = '/content/poly-yolo/poly_yolo_predict/' #path, where the images will be saved. The path must exist\n",
        "list_of_imgs = [root+\"/\"+name for root, dirs, files in os.walk(dir_imgs_name) for name in files]    \n",
        "list_of_imgs.sort()\n",
        "\n",
        "#browse all images\n",
        "total_boxes = 0\n",
        "imgs        = 0\n",
        "\n",
        "for im in range (0, len(list_of_imgs)):\n",
        "    imgs    += 1\n",
        "    img     = cv2.imread(list_of_imgs[im])\n",
        "    overlay = img.copy()\n",
        "    boxes   = []\n",
        "    scores  = []\n",
        "    classes = []\n",
        "    \n",
        "    #realize prediciction using poly-yolo\n",
        "    startx = time.time()\n",
        "    box, scores, classes, polygons = trained_model.detect_image(img)\n",
        "    print('Prediction speed: ', 1.0/(time.time() - startx), 'fps')\n",
        "    \n",
        "\n",
        "    #example, hw to reshape reshape y1,x1,y2,x2 into x1,y1,x2,y2\n",
        "\n",
        "    for k in range (0, len(box)):\n",
        "        boxes.append((box[k][1], box[k][0], box[k][3], box[k][2]))\n",
        "        cv2.rectangle(img, (box[k][1],box[k][0]), (box[k][3],box[k][2]), translate_color(classes[k]), 3, 1)\n",
        "    total_boxes += len(boxes)\n",
        "\n",
        "\n",
        "    #browse all boxes\n",
        "    for b in range(0, len(boxes)):\n",
        "        f              = translate_color(classes[b])    \n",
        "        points_to_draw = []\n",
        "        offset         = len(polygons[b])//3\n",
        "        \n",
        "        #filter bounding polygon vertices\n",
        "        for dst in range(0, len(polygons[b])//3):\n",
        "            if polygons[b][dst+offset*2] > 0.3: \n",
        "                points_to_draw.append([int(polygons[b][dst]), int(polygons[b][dst+offset])])\n",
        "        \n",
        "        points_to_draw = np.asarray(points_to_draw)\n",
        "        points_to_draw = points_to_draw.astype(np.int32)\n",
        "        if points_to_draw.shape[0]>0:\n",
        "            cv2.polylines(img, [points_to_draw],True,f, thickness=2)\n",
        "            cv2.fillPoly(overlay, [points_to_draw], f)\n",
        "    img = cv2.addWeighted(overlay, 0.4, img, 1 - 0.4, 0)\n",
        "    cv2.imwrite(out_path+str(imgs)+'.jpg', img)\n",
        "    \n",
        "print('total boxes: ', total_boxes)\n",
        "print('imgs: ', imgs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "oNVKG8rrfMZ3",
        "outputId": "65e4bfa8-dda7-424d-a52a-dc87eb7ce8f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction speed:  0.16553173432479945 fps\n",
            "Prediction speed:  36.1160728124408 fps\n",
            "Prediction speed:  40.65705727828776 fps\n",
            "Prediction speed:  42.83661172048941 fps\n",
            "Prediction speed:  41.37659442235792 fps\n",
            "Prediction speed:  40.738009673847586 fps\n",
            "Prediction speed:  40.82842402414095 fps\n",
            "Prediction speed:  40.931220235771725 fps\n",
            "Prediction speed:  42.48472018232464 fps\n",
            "Prediction speed:  41.93674948757686 fps\n",
            "Prediction speed:  40.65784550363025 fps\n",
            "Prediction speed:  42.48041727857396 fps\n",
            "Prediction speed:  43.05824863977004 fps\n",
            "Prediction speed:  40.69808556263888 fps\n",
            "Prediction speed:  43.34929100004134 fps\n",
            "Prediction speed:  43.37125544169502 fps\n",
            "Prediction speed:  43.450332017693796 fps\n",
            "Prediction speed:  42.96342125480154 fps\n",
            "Prediction speed:  42.8068828968586 fps\n",
            "Prediction speed:  42.129251290704914 fps\n",
            "Prediction speed:  43.13485607330543 fps\n",
            "Prediction speed:  42.37055893970159 fps\n",
            "Prediction speed:  45.20406095747203 fps\n",
            "Prediction speed:  45.11168473584581 fps\n",
            "Prediction speed:  43.66610448289504 fps\n",
            "Prediction speed:  44.043010752688176 fps\n",
            "Prediction speed:  44.45944456222175 fps\n",
            "Prediction speed:  43.34615503859946 fps\n",
            "Prediction speed:  45.379640148441474 fps\n",
            "Prediction speed:  44.62880125981571 fps\n",
            "Prediction speed:  43.575373490971806 fps\n",
            "Prediction speed:  45.335495098198166 fps\n",
            "Prediction speed:  43.84962154476644 fps\n",
            "Prediction speed:  41.02048919793837 fps\n",
            "Prediction speed:  43.72391506041052 fps\n",
            "Prediction speed:  42.37269916957953 fps\n",
            "Prediction speed:  43.26701052197235 fps\n",
            "Prediction speed:  43.02556316934061 fps\n",
            "Prediction speed:  40.959200015624695 fps\n",
            "Prediction speed:  43.703868877056614 fps\n",
            "Prediction speed:  44.89007331299834 fps\n",
            "Prediction speed:  42.14110318496935 fps\n",
            "Prediction speed:  41.630808933002484 fps\n",
            "Prediction speed:  37.31454396640689 fps\n",
            "Prediction speed:  41.94471778871155 fps\n",
            "Prediction speed:  42.22127822349282 fps\n",
            "Prediction speed:  41.909093634156335 fps\n",
            "Prediction speed:  41.57674884269585 fps\n",
            "Prediction speed:  42.76890760586934 fps\n",
            "Prediction speed:  43.90700011515069 fps\n",
            "Prediction speed:  38.01529927854113 fps\n",
            "Prediction speed:  42.87251615013493 fps\n",
            "Prediction speed:  40.40872086861855 fps\n",
            "Prediction speed:  42.336771979408496 fps\n",
            "Prediction speed:  42.82611448058976 fps\n",
            "Prediction speed:  41.833853641994395 fps\n",
            "Prediction speed:  40.590169645708535 fps\n",
            "Prediction speed:  38.32689724493992 fps\n",
            "Prediction speed:  41.72315895232126 fps\n",
            "Prediction speed:  44.363982526469435 fps\n",
            "Prediction speed:  38.56831264367816 fps\n",
            "Prediction speed:  41.38149313811577 fps\n",
            "Prediction speed:  41.71942388796053 fps\n",
            "Prediction speed:  39.2721416466138 fps\n",
            "Prediction speed:  39.87777027733673 fps\n",
            "Prediction speed:  43.99496517579928 fps\n",
            "Prediction speed:  42.753649188616166 fps\n",
            "Prediction speed:  41.32889265514455 fps\n",
            "Prediction speed:  42.988961431631594 fps\n",
            "Prediction speed:  42.67925718646655 fps\n",
            "Prediction speed:  42.07642225855963 fps\n",
            "Prediction speed:  38.06670720528575 fps\n",
            "Prediction speed:  43.82075954657055 fps\n",
            "Prediction speed:  42.376980278047206 fps\n",
            "Prediction speed:  42.4885935410673 fps\n",
            "Prediction speed:  42.81212616106971 fps\n",
            "Prediction speed:  43.27593891869583 fps\n",
            "Prediction speed:  33.478636367264514 fps\n",
            "Prediction speed:  42.383403563019776 fps\n",
            "Prediction speed:  39.7169073434023 fps\n",
            "Prediction speed:  42.54332633458094 fps\n",
            "Prediction speed:  39.37648097035243 fps\n",
            "Prediction speed:  38.816380546943684 fps\n",
            "Prediction speed:  39.689471791669035 fps\n",
            "Prediction speed:  40.12075529452277 fps\n",
            "Prediction speed:  38.85521598562257 fps\n",
            "Prediction speed:  35.85825304140413 fps\n",
            "Prediction speed:  36.59599863887411 fps\n",
            "Prediction speed:  43.73896177028803 fps\n",
            "Prediction speed:  41.7930031188035 fps\n",
            "Prediction speed:  42.046474326844034 fps\n",
            "Prediction speed:  39.1040835353347 fps\n",
            "Prediction speed:  41.38843497138346 fps\n",
            "Prediction speed:  41.93129923621386 fps\n",
            "Prediction speed:  42.95682097501024 fps\n",
            "Prediction speed:  42.333353519449325 fps\n",
            "Prediction speed:  42.799020408163265 fps\n",
            "Prediction speed:  37.8342413855313 fps\n",
            "Prediction speed:  42.778067885117494 fps\n",
            "Prediction speed:  42.49720353408446 fps\n",
            "Prediction speed:  43.44853162065572 fps\n",
            "Prediction speed:  35.06737899955688 fps\n",
            "Prediction speed:  41.289021893211526 fps\n",
            "Prediction speed:  40.610606016595504 fps\n",
            "Prediction speed:  39.38683444454878 fps\n",
            "Prediction speed:  40.95320112871887 fps\n",
            "Prediction speed:  40.79546360868762 fps\n",
            "Prediction speed:  40.95000244081035 fps\n",
            "Prediction speed:  40.7055900621118 fps\n",
            "Prediction speed:  41.66596135697611 fps\n",
            "Prediction speed:  42.93263728952352 fps\n",
            "Prediction speed:  41.55903452102572 fps\n",
            "Prediction speed:  40.67992822850492 fps\n",
            "Prediction speed:  41.89946455686086 fps\n",
            "Prediction speed:  42.152114487859784 fps\n",
            "Prediction speed:  38.761138167804894 fps\n",
            "Prediction speed:  42.16355539471436 fps\n",
            "Prediction speed:  42.25573241990731 fps\n",
            "Prediction speed:  42.47267424787095 fps\n",
            "Prediction speed:  41.976201198947166 fps\n",
            "Prediction speed:  42.89794832982184 fps\n",
            "Prediction speed:  42.0355181399078 fps\n",
            "Prediction speed:  42.565777322224136 fps\n",
            "Prediction speed:  42.63023946009676 fps\n",
            "Prediction speed:  42.59041429731925 fps\n",
            "Prediction speed:  40.83836229979066 fps\n",
            "Prediction speed:  41.34233585995486 fps\n",
            "Prediction speed:  41.26667912907447 fps\n",
            "Prediction speed:  39.387944068290025 fps\n",
            "Prediction speed:  40.41650847490292 fps\n",
            "Prediction speed:  38.884033114854404 fps\n",
            "Prediction speed:  42.638906961613536 fps\n",
            "Prediction speed:  41.21679998427704 fps\n",
            "Prediction speed:  41.702002425977845 fps\n",
            "Prediction speed:  39.76548219500171 fps\n",
            "Prediction speed:  40.62830795458948 fps\n",
            "Prediction speed:  41.38026835043409 fps\n",
            "Prediction speed:  42.3889719852852 fps\n",
            "Prediction speed:  42.56491338454825 fps\n",
            "Prediction speed:  42.72534099359268 fps\n",
            "Prediction speed:  39.872462996587224 fps\n",
            "Prediction speed:  44.28762697189196 fps\n",
            "Prediction speed:  42.76280293221048 fps\n",
            "Prediction speed:  37.57596172797477 fps\n",
            "Prediction speed:  40.64248062015504 fps\n",
            "Prediction speed:  39.462802841416945 fps\n",
            "Prediction speed:  39.642206343805526 fps\n",
            "Prediction speed:  39.64820206450637 fps\n",
            "Prediction speed:  39.11721256435126 fps\n",
            "Prediction speed:  39.981926504933035 fps\n",
            "Prediction speed:  39.80321894928637 fps\n",
            "Prediction speed:  40.7934797409014 fps\n",
            "Prediction speed:  38.656823439415305 fps\n",
            "Prediction speed:  42.0254098032143 fps\n",
            "Prediction speed:  42.075578070923406 fps\n",
            "Prediction speed:  43.49674368440702 fps\n",
            "Prediction speed:  38.98957936323495 fps\n",
            "Prediction speed:  42.60079629479158 fps\n",
            "Prediction speed:  42.15465637500251 fps\n",
            "Prediction speed:  41.93297608573942 fps\n",
            "Prediction speed:  42.22722925287183 fps\n",
            "Prediction speed:  41.22854924164234 fps\n",
            "Prediction speed:  42.557571330005274 fps\n",
            "Prediction speed:  41.79466892531513 fps\n",
            "Prediction speed:  40.46212618174802 fps\n",
            "Prediction speed:  42.85587003167467 fps\n",
            "Prediction speed:  37.71042221103359 fps\n",
            "Prediction speed:  40.62712734528618 fps\n",
            "Prediction speed:  40.27756277908484 fps\n",
            "Prediction speed:  41.443234590834535 fps\n",
            "Prediction speed:  40.8833437305053 fps\n",
            "Prediction speed:  38.095750188466745 fps\n",
            "Prediction speed:  41.14483029232882 fps\n",
            "Prediction speed:  42.01825267228339 fps\n",
            "Prediction speed:  41.84428748154356 fps\n",
            "Prediction speed:  43.6688322505414 fps\n",
            "Prediction speed:  42.09542544009314 fps\n",
            "Prediction speed:  41.8743660396949 fps\n",
            "Prediction speed:  37.56721123531098 fps\n",
            "Prediction speed:  42.05448438361658 fps\n",
            "Prediction speed:  40.991624397728714 fps\n",
            "Prediction speed:  41.46207987346777 fps\n",
            "Prediction speed:  42.18306162062134 fps\n",
            "Prediction speed:  37.792310534045754 fps\n",
            "Prediction speed:  41.23260226300837 fps\n",
            "Prediction speed:  43.02997722469582 fps\n",
            "Prediction speed:  39.3775900107966 fps\n",
            "Prediction speed:  41.785092350913544 fps\n",
            "Prediction speed:  34.36404899430585 fps\n",
            "Prediction speed:  40.63933028447407 fps\n",
            "Prediction speed:  39.76925265014317 fps\n",
            "Prediction speed:  38.78515285458009 fps\n",
            "Prediction speed:  39.59281075366259 fps\n",
            "Prediction speed:  39.85579216435284 fps\n",
            "Prediction speed:  40.721002708711566 fps\n",
            "Prediction speed:  40.5948839054984 fps\n",
            "Prediction speed:  40.98801915371836 fps\n",
            "Prediction speed:  41.1561347044509 fps\n",
            "Prediction speed:  42.17415436592527 fps\n",
            "Prediction speed:  40.24432695905816 fps\n",
            "Prediction speed:  41.77801683350764 fps\n",
            "Prediction speed:  42.21702851506276 fps\n",
            "Prediction speed:  42.293227927237524 fps\n",
            "Prediction speed:  42.04942504536477 fps\n",
            "Prediction speed:  41.82759583549404 fps\n",
            "Prediction speed:  42.90453052915844 fps\n",
            "Prediction speed:  42.64150789939204 fps\n",
            "Prediction speed:  38.60132343061193 fps\n",
            "Prediction speed:  42.55152683372223 fps\n",
            "Prediction speed:  40.11193037823364 fps\n",
            "Prediction speed:  42.74929164033675 fps\n",
            "Prediction speed:  39.39238318854191 fps\n",
            "Prediction speed:  35.93382623818785 fps\n",
            "Prediction speed:  42.3350626804207 fps\n",
            "Prediction speed:  42.526072453335225 fps\n",
            "Prediction speed:  42.228929855119155 fps\n",
            "Prediction speed:  43.25674741911863 fps\n",
            "Prediction speed:  43.04057465366855 fps\n",
            "Prediction speed:  40.489858961858886 fps\n",
            "Prediction speed:  40.202666564425996 fps\n",
            "Prediction speed:  40.39509977656214 fps\n",
            "Prediction speed:  39.686091950760265 fps\n",
            "Prediction speed:  40.25243761996161 fps\n",
            "Prediction speed:  41.92794593946179 fps\n",
            "Prediction speed:  40.52663413691483 fps\n",
            "Prediction speed:  43.20016479555052 fps\n",
            "Prediction speed:  38.7407311621377 fps\n",
            "Prediction speed:  40.83080876912893 fps\n",
            "Prediction speed:  42.13983302020436 fps\n",
            "Prediction speed:  40.74077959417587 fps\n",
            "Prediction speed:  39.97582943357383 fps\n",
            "Prediction speed:  36.21648879218043 fps\n",
            "Prediction speed:  39.638459939138485 fps\n",
            "Prediction speed:  39.03203111913492 fps\n",
            "Prediction speed:  40.677166576150206 fps\n",
            "Prediction speed:  38.59706079930799 fps\n",
            "Prediction speed:  39.690598533238706 fps\n",
            "Prediction speed:  41.56397653400983 fps\n",
            "Prediction speed:  36.98680776014109 fps\n",
            "Prediction speed:  40.182638602810854 fps\n",
            "Prediction speed:  41.38761816423595 fps\n",
            "Prediction speed:  39.40644700621024 fps\n",
            "Prediction speed:  39.73685008337123 fps\n",
            "Prediction speed:  41.545861563453386 fps\n",
            "Prediction speed:  41.133128695976225 fps\n",
            "Prediction speed:  41.041361292405846 fps\n",
            "Prediction speed:  41.42972569859442 fps\n",
            "Prediction speed:  39.58048108409063 fps\n",
            "Prediction speed:  41.84637487404097 fps\n",
            "Prediction speed:  43.759496708364196 fps\n",
            "Prediction speed:  41.715689492267146 fps\n",
            "Prediction speed:  41.127078757452146 fps\n",
            "Prediction speed:  40.62161874231257 fps\n",
            "Prediction speed:  40.269828620805534 fps\n",
            "Prediction speed:  41.23138627292924 fps\n",
            "Prediction speed:  40.433651779086695 fps\n",
            "Prediction speed:  38.918309022751735 fps\n",
            "Prediction speed:  41.793419557982425 fps\n",
            "Prediction speed:  42.197490869945774 fps\n",
            "Prediction speed:  41.34152087132226 fps\n",
            "Prediction speed:  42.10134104231912 fps\n",
            "Prediction speed:  41.971580674858906 fps\n",
            "Prediction speed:  41.95352838209553 fps\n",
            "Prediction speed:  35.53802224990044 fps\n",
            "Prediction speed:  40.92443091453717 fps\n",
            "Prediction speed:  42.01825267228339 fps\n",
            "Prediction speed:  41.00565082220441 fps\n",
            "Prediction speed:  41.31098197577071 fps\n",
            "Prediction speed:  41.30406609747211 fps\n",
            "Prediction speed:  39.55509869196601 fps\n",
            "Prediction speed:  41.18604057424537 fps\n",
            "Prediction speed:  40.52076127910347 fps\n",
            "Prediction speed:  39.76472818976469 fps\n",
            "Prediction speed:  40.3151156308272 fps\n",
            "Prediction speed:  39.685340953173935 fps\n",
            "Prediction speed:  37.71686524886471 fps\n",
            "Prediction speed:  37.728061022559636 fps\n",
            "Prediction speed:  40.03382679991219 fps\n",
            "Prediction speed:  34.338728560317655 fps\n",
            "Prediction speed:  40.521152750002415 fps\n",
            "Prediction speed:  39.59617472410245 fps\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-0fe0d8d30d3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillPoly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverlay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpoints_to_draw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddWeighted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverlay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.jpg'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'total boxes: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_boxes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_anchors(anchors_path):\n",
        "      \"\"\"loads the anchors from a file\"\"\"\n",
        "      with open(anchors_path) as f:\n",
        "          anchors = f.readline()\n",
        "      anchors = [float(x) for x in anchors.split(',')]\n",
        "      return np.array(anchors).reshape(-1, 2)\n",
        "\n",
        "\n",
        "anchors = get_anchors(\"/content/poly-yolo/yolo_anchors.txt\")\n",
        "with open(\"/content/poly-yolo/simulator_dataset/simulator-test.txt\") as f:\n",
        " lines = f.readlines()\n",
        "line = lines[0].strip(\" \")\n",
        "image = cv.imread(os.path.join(\"/content/poly-yolo/simulator_dataset/imgs\", line[0:13]))\n",
        "iw = image.shape[1]\n",
        "ih = image.shape[0]\n",
        "iw"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BA48CHss8TXq",
        "outputId": "92560788-c6c7-4ece-c229-768e5c615db4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "800"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "import colorsys\n",
        "import os\n",
        "import sys\n",
        "from functools import reduce\n",
        "from functools import wraps\n",
        "\n",
        "import math\n",
        "import random as rd\n",
        "import cv2 as cv\n",
        "import keras.backend as K\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, Callback\n",
        "from keras.layers import Conv2D, Add, ZeroPadding2D, UpSampling2D, Concatenate\n",
        "from keras.layers import Input, GlobalAveragePooling2D, Reshape, Dense, Permute, multiply, Activation, add, Lambda, concatenate, MaxPooling2D\n",
        "from keras.layers import Input, Lambda\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.models import load_model\n",
        "from keras.optimizers import Adadelta, Adagrad\n",
        "from keras.regularizers import l2\n",
        "from keras.utils import multi_gpu_model\n",
        "from matplotlib.colors import rgb_to_hsv, hsv_to_rgb\n",
        "\n",
        "np.set_printoptions(precision=3, suppress=True)\n",
        "MAX_VERTICES = 1000 #that allows the labels to have 1000 vertices per polygon at max. They are reduced for training\n",
        "ANGLE_STEP  = 15 #that means Poly-YOLO will detect 360/15=24 vertices per polygon at max\n",
        "NUM_ANGLES3  = int(360 // ANGLE_STEP * 3)\n",
        "NUM_ANGLES  = int(360 // ANGLE_STEP)\n",
        "\n",
        "grid_size_multiplier = 4 #that is resolution of the output scale compared with input. So it is 1/4\n",
        "anchor_mask = [[0,1,2,3,4,5,6,7,8], [0,1,2,3,4,5,6,7,8], [0,1,2,3,4,5,6,7,8]] #that should be optimized\n",
        "anchors_per_level = 9 #single scale and nine anchors\n",
        "all_ious = []\n",
        "all_losses = []\n",
        "def compose(*funcs):\n",
        "    \"\"\"Compose arbitrarily many functions, evaluated left to right.\n",
        "\n",
        "    Reference: https://mathieularose.com/function-composition-in-python/\n",
        "    \"\"\"\n",
        "    # return lambda x: reduce(lambda v, f: f(v), funcs, x)\n",
        "    if funcs:\n",
        "        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)\n",
        "    else:\n",
        "        raise ValueError('Composition of empty sequence not supported.')\n",
        "\n",
        "\n",
        "def letterbox_image(image, size):\n",
        "    '''resize image with unchanged aspect ratio using padding'''\n",
        "    iw = image.shape[1]\n",
        "    ih = image.shape[0]\n",
        "    w, h = size\n",
        "    scale = min(w / iw, h / ih)\n",
        "    nw = int(iw * scale)\n",
        "    nh = int(ih * scale)\n",
        "\n",
        "    cvi = cv.cvtColor(image, cv.COLOR_BGR2RGB)\n",
        "    cvi = cv.resize(cvi, (nw, nh), interpolation=cv.INTER_CUBIC)\n",
        "    dx = int((w - nw) // 2)\n",
        "    dy = int((h - nh) // 2)\n",
        "    new_image = np.zeros((h, w, 3), dtype='uint8')\n",
        "    new_image[...] = 128\n",
        "    if nw <= w and nh <= h:\n",
        "        new_image[dy:dy + nh, dx:dx + nw, :] = cvi\n",
        "    else:\n",
        "        new_image = cvi[-dy:-dy + h, -dx:-dx + w, :]\n",
        "\n",
        "    return new_image.astype('float32') / 255.0\n",
        "\n",
        "\n",
        "def rand(a=0, b=1):\n",
        "    return np.random.rand() * (b - a) + a\n",
        "\n",
        "\n",
        "def get_random_data(line, input_shape, random=True, max_boxes=80, hue_alter=20, sat_alter=30, val_alter=30, proc_img=True):\n",
        "    # load data\n",
        "    # the color conversion is later. it is not necessary to realize bgr->rgb->hsv->rgb\n",
        "    path = os.path.join(\"/content/poly-yolo/poly_yolo/train\", line[0])\n",
        "    image = cv.imread(path)\n",
        "    iw = image.shape[1]\n",
        "    ih = image.shape[0]\n",
        "    h, w = input_shape\n",
        "    box = np.array([np.array(list(map(float, box.split(','))))\n",
        "                    for box in line[1:]])\n",
        "\n",
        "    if not random:\n",
        "        # resize image\n",
        "        scale = min(w / iw, h / ih)\n",
        "        nw = int(iw * scale)\n",
        "        nh = int(ih * scale)\n",
        "        dx = (w - nw) // 2\n",
        "        dy = (h - nh) // 2\n",
        "        image_data = 0\n",
        "        if proc_img:\n",
        "            # image = image.resize((nw, nh), Image.BICUBIC)\n",
        "            image = cv.cvtColor(\n",
        "                cv.resize(image, (nw, nh), interpolation=cv.INTER_CUBIC), cv.COLOR_BGR2RGB)\n",
        "            image = Image.fromarray(image)\n",
        "            new_image = Image.new('RGB', (w, h), (128, 128, 128))\n",
        "            new_image.paste(image, (dx, dy))\n",
        "            image_data = np.array(new_image) / 255.\n",
        "        # correct boxes\n",
        "        box_data = np.zeros((max_boxes, 5 + NUM_ANGLES3))\n",
        "        if len(box) > 0:\n",
        "            np.random.shuffle(box)\n",
        "            if len(box) > max_boxes:\n",
        "                box = box[:max_boxes]\n",
        "            box[:, [0, 2]] = box[:, [0, 2]] * scale + dx\n",
        "            box[:, [1, 3]] = box[:, [1, 3]] * scale + dy\n",
        "            box_data[:len(box), 0:5] = box[:, 0:5]\n",
        "            for b in range(0, len(box)):\n",
        "                for i in range(5, MAX_VERTICES * 2, 2):\n",
        "                    if box[b,i] == 0 and box[b, i + 1] == 0:\n",
        "                        continue\n",
        "                    box[b, i] = box[b, i] * scale + dx\n",
        "                    box[b, i + 1] = box[b, i + 1] * scale + dy\n",
        "\n",
        "\n",
        "            for i in range(0, len(box)):\n",
        "                boxes_xy = (box[i, 0:2] + box[i, 2:4]) // 2\n",
        "\n",
        "                for ver in range(5, MAX_VERTICES * 2, 2):\n",
        "                    if box[i, ver] == 0 and box[i, ver + 1] == 0:\n",
        "                        break\n",
        "                    dist_x = boxes_xy[0] - box[i, ver]\n",
        "                    dist_y = boxes_xy[1] - box[i, ver + 1]\n",
        "                    dist = np.sqrt(np.power(dist_x, 2) + np.power(dist_y, 2))\n",
        "                    if (dist < 1): dist = 1 #to avoid inf or nan in log in loss\n",
        "\n",
        "                    angle = np.degrees(np.arctan2(dist_y, dist_x))\n",
        "                    if (angle < 0): angle += 360\n",
        "                    iangle = int(angle) // ANGLE_STEP\n",
        "                    relative_angle = (angle - (iangle * int(ANGLE_STEP))) / ANGLE_STEP\n",
        "\n",
        "                    if dist > box_data[i, 5 + iangle * 3]:  # check for vertex existence. only the most distant is taken\n",
        "                        box_data[i, 5 + iangle * 3] = dist\n",
        "                        box_data[i, 5 + iangle * 3 + 1] = relative_angle\n",
        "                        box_data[i, 5 + iangle * 3 + 2] = 1\n",
        "        return image_data, box_data\n",
        "\n",
        "\n",
        "    # resize image\n",
        "    random_scale = rd.uniform(.6, 1.6)\n",
        "    scale = min(w / iw, h / ih)\n",
        "    nw = int(iw * scale * random_scale)\n",
        "    nh = int(ih * scale * random_scale)\n",
        "\n",
        "    # force nw a nh to be an even\n",
        "    if (nw % 2) == 1:\n",
        "        nw = nw + 1\n",
        "    if (nh % 2) == 1:\n",
        "        nh = nh + 1\n",
        "\n",
        "    # jitter for slight distort of aspect ratio\n",
        "    if np.random.rand() < 0.3:\n",
        "        if np.random.rand() < 0.5:\n",
        "            nw = int(nw*rd.uniform(.8, 1.0))\n",
        "        else:\n",
        "            nh = int(nh*rd.uniform(.8, 1.0))\n",
        "\n",
        "    image = cv.resize(image, (nw, nh), interpolation=cv.INTER_CUBIC)\n",
        "    nwiw = nw/iw\n",
        "    nhih = nh/ih\n",
        "\n",
        "    # clahe. applied on resized image to save time. but before placing to avoid\n",
        "    # the influence of homogenous background\n",
        "    if np.random.rand() < 0.05:\n",
        "        clahe = cv.createCLAHE(clipLimit=2, tileGridSize=(8, 8))\n",
        "        lab = cv.cvtColor(image, cv.COLOR_BGR2LAB)\n",
        "        l, a, b = cv.split(lab)\n",
        "        cl = clahe.apply(l)\n",
        "        limg = cv.merge((cl, a, b))\n",
        "        image = cv.cvtColor(limg, cv.COLOR_LAB2BGR)\n",
        "\n",
        "    # place image\n",
        "    dx = rd.randint(0, max(w - nw, 0))\n",
        "    dy = rd.randint(0, max(h - nh, 0))\n",
        "\n",
        "    new_image = np.full((h, w, 3), 128, dtype='uint8')\n",
        "    new_image, crop_coords, new_img_coords = random_crop(\n",
        "        image, new_image)\n",
        "\n",
        "    # flip image or not\n",
        "    flip = rd.random() < .5\n",
        "    if flip:\n",
        "        new_image = cv.flip(new_image, 1)\n",
        "\n",
        "    # distort image\n",
        "    hsv = np.int32(cv.cvtColor(new_image, cv.COLOR_BGR2HSV))\n",
        "\n",
        "    # linear hsv distortion\n",
        "    hsv[..., 0] += rd.randint(-hue_alter, hue_alter)\n",
        "    hsv[..., 1] += rd.randint(-sat_alter, sat_alter)\n",
        "    hsv[..., 2] += rd.randint(-val_alter, val_alter)\n",
        "\n",
        "    # additional non-linear distortion of saturation and value\n",
        "    if np.random.rand() < 0.5:\n",
        "        hsv[..., 1] = hsv[..., 1]*rd.uniform(.7, 1.3)\n",
        "        hsv[..., 2] = hsv[..., 2]*rd.uniform(.7, 1.3)\n",
        "\n",
        "    hsv[..., 0][hsv[..., 0] > 179] = 179\n",
        "    hsv[..., 0][hsv[..., 0] < 0] = 0\n",
        "    hsv[..., 1][hsv[..., 1] > 255] = 255\n",
        "    hsv[..., 1][hsv[..., 1] < 0] = 0\n",
        "    hsv[..., 2][hsv[..., 2] > 255] = 255\n",
        "    hsv[..., 2][hsv[..., 2] < 0] = 0\n",
        "\n",
        "    image_data = cv.cvtColor(\n",
        "        np.uint8(hsv), cv.COLOR_HSV2RGB).astype('float32') / 255.0\n",
        "\n",
        "    # add noise\n",
        "    if np.random.rand() < 0.15:\n",
        "        image_data = np.clip(image_data + np.random.rand() *\n",
        "                             image_data.std() * np.random.random(image_data.shape), 0, 1)\n",
        "\n",
        "    # correct boxes\n",
        "    box_data = np.zeros((max_boxes, 5 + NUM_ANGLES3))\n",
        "\n",
        "    if len(box) > 0:\n",
        "        np.random.shuffle(box)\n",
        "        # rescaling separately because 5-th element is class\n",
        "        box[:, [0, 2]] = box[:, [0, 2]] * nwiw\n",
        "        # rescale polygon vertices\n",
        "        box[:, 5::2] = box[:, 5::2] * nwiw\n",
        "        # rescale polygon vertices\n",
        "        box[:, [1, 3]] = box[:, [1, 3]] * nhih\n",
        "        box[:, 6::2] = box[:, 6::2] * nhih\n",
        "\n",
        "        # transform boxes to new coordinate system w.r.t new_image\n",
        "        box[:, :2] = box[:, :2] - [crop_coords[2], crop_coords[0]] + [new_img_coords[2], new_img_coords[0]]\n",
        "        box[:, 2:4] = box[:, 2:4] - [crop_coords[2], crop_coords[0]] + [new_img_coords[2], new_img_coords[0]]\n",
        "        if flip:\n",
        "            box[:, [0, 2]] = (w-1) - box[:, [2, 0]]\n",
        "\n",
        "        box[:, 0:2][box[:, 0:2] < 0] = 0\n",
        "        box[:, 2][box[:, 2] >= w] = w-1\n",
        "        box[:, 3][box[:, 3] >= h] = h-1\n",
        "        box_w = box[:, 2] - box[:, 0]\n",
        "        box_h = box[:, 3] - box[:, 1]\n",
        "        box = box[np.logical_and(box_w > 1, box_h > 1)]  # discard invalid box\n",
        "\n",
        "        if len(box) > max_boxes:\n",
        "            box = box[:max_boxes]\n",
        "\n",
        "        box_data[:len(box), 0:5] = box[:, 0:5]\n",
        "\n",
        "    #-------------------------------start polygon vertices processing-------------------------------#\n",
        "    for b in range(0, len(box)):\n",
        "        boxes_xy = (box[b, 0:2] + box[b, 2:4]) // 2\n",
        "        for i in range(5, MAX_VERTICES * 2, 2):\n",
        "            if box[b, i] == 0 and box[b, i + 1] == 0:\n",
        "                break\n",
        "            box[b, i:i+2] = box[b, i:i+2] - [crop_coords[2], crop_coords[0]] + [new_img_coords[2], new_img_coords[0]]\n",
        "            if flip: box[b, i] = (w - 1) - box[b, i]\n",
        "            dist_x = boxes_xy[0] - box[b, i]\n",
        "            dist_y = boxes_xy[1] - box[b, i + 1]\n",
        "            dist = np.sqrt(np.power(dist_x, 2) + np.power(dist_y, 2))\n",
        "            if (dist < 1): dist = 1\n",
        "\n",
        "            angle = np.degrees(np.arctan2(dist_y, dist_x))\n",
        "            if (angle < 0): angle += 360\n",
        "            iangle = int(angle) // ANGLE_STEP\n",
        "            if iangle>=NUM_ANGLES: iangle = NUM_ANGLES-1\n",
        "\n",
        "            if dist > box_data[b, 5 + iangle * 3]: # check for vertex existence. only the most distant is taken\n",
        "                box_data[b, 5 + iangle * 3]     = dist\n",
        "                box_data[b, 5 + iangle * 3 + 1] = (angle - (iangle * int(ANGLE_STEP))) / ANGLE_STEP #relative angle\n",
        "                box_data[b, 5 + iangle * 3 + 2] = 1\n",
        "    #---------------------------------end polygon vertices processing-------------------------------#\n",
        "    return image_data, box_data\n",
        "\n",
        "\n",
        "def random_crop(img, new_img):\n",
        "    \"\"\"Creates random crop from img and insert it into new_img\n",
        "\n",
        "    Args:\n",
        "        img (numpy array): Image to be cropped\n",
        "        new_img (numpy array): Image to which the crop will be inserted into.\n",
        "\n",
        "    Returns:\n",
        "        tuple: Tuple of image containing the crop, list of coordinates used to crop img and list of coordinates where the crop\n",
        "        has been inserted into in new_img\n",
        "    \"\"\"\n",
        "    h, w = img.shape[:2]\n",
        "    crop_shape = new_img.shape[:2]\n",
        "    crop_coords = [0, 0, 0, 0]\n",
        "    new_pos = [0, 0, 0, 0]\n",
        "    # if image height is smaller than cropping window\n",
        "    if h < crop_shape[0]:\n",
        "        # cropping whole image [0,h]\n",
        "        crop_coords[1] = h\n",
        "        # randomly position whole img along height dimension\n",
        "        val = rd.randint(0, crop_shape[0]-h)\n",
        "        new_pos[0:2] = [val, val + h]\n",
        "    else:\n",
        "        # if image height is bigger than cropping window\n",
        "        # randomly position cropping window on image\n",
        "        crop_h_shift = rd.randint(crop_shape[0], h)\n",
        "        crop_coords[0:2] = [crop_h_shift - crop_shape[0], crop_h_shift]\n",
        "        new_pos[0:2] = [0, crop_shape[0]]\n",
        "\n",
        "    # same as above for image width\n",
        "    if w < crop_shape[1]:\n",
        "        crop_coords[3] = w\n",
        "        val = rd.randint(0, crop_shape[1] - w)\n",
        "        new_pos[2:4] = [val, val + w]\n",
        "    else:\n",
        "        crop_w_shift = rd.randint(crop_shape[1], w)\n",
        "        crop_coords[2:4] = [crop_w_shift - crop_shape[1], crop_w_shift]\n",
        "        new_pos[2:4] = [0, crop_shape[1]]\n",
        "\n",
        "    # slice, insert and return image including crop and coordinates used for cropping and inserting\n",
        "    # coordinates are later used for boxes adjustments.\n",
        "    new_img[new_pos[0]:new_pos[1], new_pos[2]:new_pos[3],\n",
        "            :] = img[crop_coords[0]:crop_coords[1], crop_coords[2]:crop_coords[3], :]\n",
        "    return new_img, crop_coords, new_pos\n",
        "\n",
        "\n",
        "@wraps(Conv2D)\n",
        "def DarknetConv2D(*args, **kwargs):\n",
        "    \"\"\"Wrapper to set Darknet parameters for Convolution2D.\"\"\"\n",
        "    darknet_conv_kwargs = {'kernel_regularizer': l2(5e-4)}\n",
        "    darknet_conv_kwargs['padding'] = 'valid' if kwargs.get('strides') == (2, 2) else 'same'\n",
        "    darknet_conv_kwargs.update(kwargs)\n",
        "    return Conv2D(*args, **darknet_conv_kwargs)\n",
        "\n",
        "\n",
        "def DarknetConv2D_BN_Leaky(*args, **kwargs):\n",
        "    \"\"\"Darknet Convolution2D followed by BatchNormalization and LeakyReLU.\"\"\"\n",
        "    no_bias_kwargs = {'use_bias': False}\n",
        "    no_bias_kwargs.update(kwargs)\n",
        "    return compose(\n",
        "        DarknetConv2D(*args, **no_bias_kwargs),\n",
        "        BatchNormalization(),\n",
        "        LeakyReLU(alpha=0.1))\n",
        "\n",
        "\n",
        "def resblock_body(x, num_filters, num_blocks):\n",
        "    '''A series of resblocks starting with a downsampling Convolution2D'''\n",
        "    # Darknet uses left and top padding instead of 'same' mode\n",
        "    x = ZeroPadding2D(((1, 0), (1, 0)))(x)\n",
        "    x = DarknetConv2D_BN_Leaky(num_filters, (3, 3), strides=(2, 2))(x)\n",
        "    for i in range(num_blocks):\n",
        "        y = compose(\n",
        "            DarknetConv2D_BN_Leaky(num_filters // 2, (1, 1)),\n",
        "            DarknetConv2D_BN_Leaky(num_filters, (3, 3)))(x)\n",
        "        y = squeeze_excite_block(y)\n",
        "        x = Add()([x, y])\n",
        "    return x\n",
        "\n",
        "\n",
        "#taken from https://github.com/titu1994/keras-squeeze-excite-network/blob/master/keras_squeeze_excite_network/se_resnet.py\n",
        "def squeeze_excite_block(tensor, ratio=16):\n",
        "    init = tensor\n",
        "    channel_axis = 1 if K.image_data_format() == \"channels_first\" else -1\n",
        "    filters = init._keras_shape[channel_axis]\n",
        "    se_shape = (1, 1, filters)\n",
        "\n",
        "    se = GlobalAveragePooling2D()(init)\n",
        "    se = Reshape(se_shape)(se)\n",
        "    se = Dense(filters // ratio, kernel_initializer='he_normal', use_bias=False)(se)\n",
        "    se = LeakyReLU(alpha=0.1)(se)\n",
        "    se = Dense(filters, activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(se)\n",
        "\n",
        "    if K.image_data_format() == 'channels_first':\n",
        "        se = Permute((3, 1, 2))(se)\n",
        "\n",
        "    x = multiply([init, se])\n",
        "    return x\n",
        "\n",
        "\n",
        "def _tensor_shape(tensor):\n",
        "    return getattr(tensor, '_keras_shape')\n",
        "\n",
        "\n",
        "\n",
        "def darknet_body(x):\n",
        "    '''Darknent body having 52 Convolution2D layers'''\n",
        "    base = 6  # YOLOv3 has base=8, we have less parameters\n",
        "    x = DarknetConv2D_BN_Leaky(base * 4, (3, 3))(x)\n",
        "    x = resblock_body(x, base * 8, 1)\n",
        "    x = resblock_body(x, base * 16, 2)\n",
        "    tiny = x\n",
        "    x = resblock_body(x, base * 32, 8)\n",
        "    small = x\n",
        "    x = resblock_body(x, base * 64, 8)\n",
        "    medium = x\n",
        "    x = resblock_body(x, base * 128, 8)\n",
        "    big = x\n",
        "    return tiny, small, medium, big\n",
        "\n",
        "\n",
        "\n",
        "def yolo_body(inputs, num_anchors, num_classes):\n",
        "    \"\"\"Create Poly-YOLO model CNN body in Keras.\"\"\"\n",
        "    tiny, small, medium, big = darknet_body(inputs)\n",
        "\n",
        "    base = 6\n",
        "    tiny   = DarknetConv2D_BN_Leaky(base*32, (1, 1))(tiny)\n",
        "    small  = DarknetConv2D_BN_Leaky(base*32, (1, 1))(small)\n",
        "    medium = DarknetConv2D_BN_Leaky(base*32, (1, 1))(medium)\n",
        "    big    = DarknetConv2D_BN_Leaky(base*32, (1, 1))(big)\n",
        "\n",
        "    #stairstep upsamplig\n",
        "    all = Add()([medium, UpSampling2D(2,interpolation='bilinear')(big)])\n",
        "    all = Add()([small, UpSampling2D(2,interpolation='bilinear')(all)])\n",
        "    all = Add()([tiny, UpSampling2D(2,interpolation='bilinear')(all)])\n",
        "\n",
        "\n",
        "\n",
        "    num_filters = base*32\n",
        "\n",
        "    x = compose(\n",
        "        DarknetConv2D_BN_Leaky(num_filters, (1, 1)),\n",
        "        DarknetConv2D_BN_Leaky(num_filters * 2, (3, 3)),\n",
        "        DarknetConv2D_BN_Leaky(num_filters, (1, 1)))(all)\n",
        "\n",
        "    all = compose(\n",
        "        DarknetConv2D_BN_Leaky(num_filters * 2, (3, 3)),\n",
        "        DarknetConv2D(num_anchors * (num_classes + 5 + NUM_ANGLES3), (1, 1)))(x)\n",
        "\n",
        "    return Model(inputs, all)\n",
        "\n",
        "\n",
        "\n",
        "def yolo_head(feats, anchors, num_classes, input_shape, calc_loss=False):\n",
        "    \"\"\"Convert final layer features to bounding box parameters.\"\"\"\n",
        "    num_anchors = anchors_per_level\n",
        "    # Reshape to batch, height, width, num_anchors, box_params.\n",
        "    anchors_tensor = K.reshape(K.constant(anchors), [1, 1, 1, num_anchors, 2])\n",
        "\n",
        "    grid_shape = K.shape(feats)[1:3]  # height, width\n",
        "    grid_y = K.tile(tf.reshape(K.arange(0, stop=grid_shape[0]), [-1, 1, 1, 1], name='yolo_head/tile/reshape/grid_y'),\n",
        "                    [1, grid_shape[1], 1, 1])\n",
        "    grid_x = K.tile(tf.reshape(K.arange(0, stop=grid_shape[1]), [1, -1, 1, 1], name='yolo_head/tile/reshape/grid_x'),\n",
        "                    [grid_shape[0], 1, 1, 1])\n",
        "    grid = tf.concat([grid_x, grid_y], axis=-1, name='yolo_head/concatenate/grid')\n",
        "    grid = K.cast(grid, K.dtype(feats))\n",
        "    feats = tf.reshape(\n",
        "        feats, [-1, grid_shape[0], grid_shape[1], num_anchors, num_classes + 5 + NUM_ANGLES3], name='yolo_head/reshape/feats')\n",
        "\n",
        "    # Adjust predictions to each spatial grid point and anchor size.\n",
        "    box_xy = (K.sigmoid(feats[..., :2]) + grid) / K.cast(grid_shape[...,::-1], K.dtype(feats))\n",
        "    box_wh = K.exp(feats[..., 2:4]) * anchors_tensor / K.cast(input_shape[...,::-1], K.dtype(feats))\n",
        "\n",
        "    box_confidence      = K.sigmoid(feats[..., 4:5])\n",
        "    box_class_probs     = K.sigmoid(feats[..., 5:5 + num_classes])\n",
        "    polygons_confidence = K.sigmoid(feats[..., 5+num_classes+2:5+num_classes+NUM_ANGLES3:3])\n",
        "    polygons_x = K.exp(feats[..., 5 + num_classes:num_classes + 5 + NUM_ANGLES3:3])\n",
        "\n",
        "    dx = K.square(anchors_tensor[..., 0:1] / 2)\n",
        "    dy = K.square(anchors_tensor[..., 1:2] / 2)\n",
        "    d = K.cast(K.sqrt(dx + dy), K.dtype(polygons_x))\n",
        "    a = K.pow(input_shape[::-1], 2)\n",
        "    a = K.cast(a, K.dtype(feats))\n",
        "    b= K.sum(a)\n",
        "    diagonal =  K.cast(K.sqrt(b), K.dtype(feats))\n",
        "    polygons_x = polygons_x * d / diagonal\n",
        "\n",
        "    polygons_y = feats[..., 5 + num_classes + 1:num_classes + 5 + NUM_ANGLES3:3]\n",
        "    polygons_y = K.sigmoid(polygons_y)\n",
        "\n",
        "    if calc_loss == True:\n",
        "        return grid, feats, box_xy, box_wh, polygons_confidence\n",
        "    return box_xy, box_wh, box_confidence, box_class_probs, polygons_x, polygons_y, polygons_confidence\n",
        "\n",
        "\n",
        "def yolo_correct_boxes(box_xy, box_wh, input_shape, image_shape):\n",
        "    '''Get corrected boxes'''\n",
        "    box_yx = box_xy[..., ::-1]\n",
        "    box_hw = box_wh[..., ::-1]\n",
        "    input_shape = K.cast(input_shape, K.dtype(box_yx))\n",
        "    image_shape = K.cast(image_shape, K.dtype(box_yx))\n",
        "    new_shape = K.round(image_shape * K.min(input_shape / image_shape))\n",
        "    offset = (input_shape - new_shape) / 2. / input_shape\n",
        "    scale = input_shape / new_shape\n",
        "    box_yx = (box_yx - offset) * scale\n",
        "    box_hw *= scale\n",
        "\n",
        "    box_mins = box_yx - (box_hw / 2.)\n",
        "    box_maxes = box_yx + (box_hw / 2.)\n",
        "    boxes = K.concatenate([\n",
        "        box_mins[..., 0:1],  # y_min\n",
        "        box_mins[..., 1:2],  # x_min\n",
        "        box_maxes[..., 0:1],  # y_max\n",
        "        box_maxes[..., 1:2]  # x_max\n",
        "    ])\n",
        "\n",
        "    # Scale boxes back to original image shape.\n",
        "    boxes *= K.concatenate([image_shape, image_shape])\n",
        "    return boxes\n",
        "\n",
        "\n",
        "def yolo_correct_polygons(polygons_x, polygons_y, polygons_confidence, boxes, input_shape, image_shape):\n",
        "    polygons = K.concatenate([polygons_x, polygons_y, polygons_confidence])\n",
        "    return polygons\n",
        "\n",
        "\n",
        "def yolo_boxes_and_scores(feats, anchors, num_classes, input_shape, image_shape):\n",
        "    '''Process Conv layer output'''\n",
        "    box_xy, box_wh, box_confidence, box_class_probs, polygons_x, polygons_y, polygons_confidence = yolo_head(feats, anchors, num_classes, input_shape)\n",
        "    boxes = yolo_correct_boxes(box_xy, box_wh, input_shape, image_shape)\n",
        "    boxes = K.reshape(boxes, [-1, 4])\n",
        "    box_scores = box_confidence * box_class_probs\n",
        "    box_scores = K.reshape(box_scores, [-1, num_classes])\n",
        "    polygons = yolo_correct_polygons(polygons_x, polygons_y, polygons_confidence, boxes, input_shape, image_shape)\n",
        "    polygons = K.reshape(polygons, [-1, NUM_ANGLES3])\n",
        "    return boxes, box_scores, polygons\n",
        "\n",
        "\n",
        "def yolo_eval(yolo_outputs,\n",
        "              anchors,\n",
        "              num_classes,\n",
        "              image_shape,\n",
        "              max_boxes=80,\n",
        "              score_threshold=.5,\n",
        "              iou_threshold=.5):\n",
        "    \"\"\"Evaluate YOLO model on given input and return filtered boxes.\"\"\"\n",
        "    input_shape = K.shape(yolo_outputs)[1:3] * grid_size_multiplier\n",
        "    boxes = []\n",
        "    box_scores = []\n",
        "    polygons = []\n",
        "\n",
        "    for l in range(1):\n",
        "        _boxes, _box_scores, _polygons = yolo_boxes_and_scores(yolo_outputs,\n",
        "                                                               anchors[anchor_mask[l]], num_classes, input_shape,\n",
        "                                                               image_shape)\n",
        "        boxes.append(_boxes)\n",
        "        box_scores.append(_box_scores)\n",
        "        polygons.append(_polygons)\n",
        "    boxes = K.concatenate(boxes, axis=0)\n",
        "    box_scores = K.concatenate(box_scores, axis=0)\n",
        "    polygons = K.concatenate(polygons, axis=0)\n",
        "\n",
        "    mask = box_scores >= score_threshold\n",
        "    box_scores >= score_threshold\n",
        "    max_boxes_tensor = K.constant(max_boxes, dtype='int32')\n",
        "    boxes_ = []\n",
        "    scores_ = []\n",
        "    classes_ = []\n",
        "    polygons_ = []\n",
        "    for c in range(num_classes):\n",
        "        # TODO: use keras backend instead of tf.\n",
        "        class_boxes = tf.boolean_mask(boxes, mask[:, c])\n",
        "        class_polygons = tf.boolean_mask(polygons, mask[:, c])\n",
        "        class_box_scores = tf.boolean_mask(box_scores[:, c], mask[:, c])\n",
        "        nms_index = tf.image.non_max_suppression(\n",
        "            class_boxes, class_box_scores, max_boxes_tensor, iou_threshold=iou_threshold)\n",
        "        class_boxes = K.gather(class_boxes, nms_index)\n",
        "        class_box_scores = K.gather(class_box_scores, nms_index)\n",
        "        class_polygons = K.gather(class_polygons, nms_index)\n",
        "        classes = K.ones_like(class_box_scores, 'int32') * c\n",
        "        boxes_.append(class_boxes)\n",
        "        scores_.append(class_box_scores)\n",
        "        classes_.append(classes)\n",
        "        polygons_.append(class_polygons)\n",
        "    polygons_ = K.concatenate(polygons_, axis=0)\n",
        "    boxes_ = K.concatenate(boxes_, axis=0)\n",
        "    scores_ = K.concatenate(scores_, axis=0)\n",
        "    classes_ = K.concatenate(classes_, axis=0)\n",
        "\n",
        "    return boxes_, scores_, classes_, polygons_\n",
        "\n",
        "\n",
        "def preprocess_true_boxes(true_boxes, input_shape, anchors, num_classes):\n",
        "    '''Preprocess true boxes to training input format\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    true_boxes: array, shape=(m, T, 5+69)\n",
        "        Absolute x_min, y_min, x_max, y_max, class_id relative to input_shape\n",
        "    input_shape: array-like, hw, multiples of 32\n",
        "    anchors: array, shape=(N, 2), wh\n",
        "    num_classes: integer\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    y_true: list of array, shape like yolo_outputs, xywh are reletive value\n",
        "\n",
        "    '''\n",
        "    assert (true_boxes[..., 4] < num_classes).all(), 'class id must be less than num_classes'\n",
        "    true_boxes = np.array(true_boxes, dtype='float32')\n",
        "    input_shape = np.array(input_shape, dtype='int32')\n",
        "    boxes_xy = (true_boxes[..., 0:2] + true_boxes[..., 2:4]) // 2\n",
        "    boxes_wh = true_boxes[..., 2:4] - true_boxes[..., 0:2]\n",
        "\n",
        "    true_boxes[:,:, 5:NUM_ANGLES3 + 5:3] /= np.clip(np.expand_dims(np.sqrt(np.power(boxes_wh[:, :, 0], 2) + np.power(boxes_wh[:, :, 1], 2)), -1), 0.0001, 9999999)\n",
        "    true_boxes[..., 0:2] = boxes_xy / input_shape[::-1]\n",
        "    true_boxes[..., 2:4] = boxes_wh / input_shape[::-1]\n",
        "\n",
        "    m = true_boxes.shape[0]\n",
        "    grid_shapes = [input_shape // {0: grid_size_multiplier}[l] for l in range(1)]\n",
        "    y_true = [np.zeros((m, grid_shapes[l][0], grid_shapes[l][1], len(anchor_mask[l]), 5 + num_classes + NUM_ANGLES3),\n",
        "                       dtype='float32') for l in range(1)]\n",
        "\n",
        "\n",
        "    # Expand dim to apply broadcasting.\n",
        "    anchors = np.expand_dims(anchors, 0)\n",
        "    anchor_maxes = anchors / 2.\n",
        "    anchor_mins = -anchor_maxes\n",
        "    valid_mask = boxes_wh[..., 0] > 0\n",
        "\n",
        "\n",
        "    for b in range(m):\n",
        "        # Discard zero rows.\n",
        "        wh = boxes_wh[b, valid_mask[b]]\n",
        "        if len(wh) == 0: continue\n",
        "        # Expand dim to apply broadcasting.\n",
        "        wh = np.expand_dims(wh, -2)\n",
        "        box_maxes = wh / 2.\n",
        "        box_mins = -box_maxes\n",
        "\n",
        "        intersect_mins = np.maximum(box_mins, anchor_mins)\n",
        "        intersect_maxes = np.minimum(box_maxes, anchor_maxes)\n",
        "        intersect_wh = np.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "        intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "        box_area = wh[..., 0] * wh[..., 1]\n",
        "        anchor_area = anchors[..., 0] * anchors[..., 1]\n",
        "        iou = intersect_area / (box_area + anchor_area - intersect_area)\n",
        "\n",
        "        # Find best anchor for each true box\n",
        "        best_anchor = np.argmax(iou, axis=-1)\n",
        "        for t, n in enumerate(best_anchor):\n",
        "            l = 0\n",
        "            if n in anchor_mask[l]:\n",
        "                i = np.floor(true_boxes[b, t, 0] * grid_shapes[l][1]).astype('int32')\n",
        "                j = np.floor(true_boxes[b, t, 1] * grid_shapes[l][0]).astype('int32')\n",
        "                k = anchor_mask[l].index(n)\n",
        "                c = true_boxes[b, t, 4].astype('int32')\n",
        "\n",
        "                y_true[l][b, j, i, k, 0:4] = true_boxes[b, t, 0:4]\n",
        "                y_true[l][b, j, i, k, 4] = 1\n",
        "                y_true[l][b, j, i, k, 5 + c] = 1\n",
        "                y_true[l][b, j, i, k, 5 + num_classes:5 + num_classes + NUM_ANGLES3] = true_boxes[b, t, 5: 5 + NUM_ANGLES3]\n",
        "    return y_true\n",
        "\n",
        "\n",
        "def box_iou(b1, b2):\n",
        "    \"\"\"Return iou tensor\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    b1: tensor, shape=(i1,...,iN, 4), xywh\n",
        "    b2: tensor, shape=(j, 4), xywh\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    iou: tensor, shape=(i1,...,iN, j)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    # Expand dim to apply broadcasting.\n",
        "    b1 = K.expand_dims(b1, -2)\n",
        "    b1_xy = b1[..., :2]\n",
        "    b1_wh = b1[..., 2:4]\n",
        "    b1_wh_half = b1_wh / 2.\n",
        "    b1_mins = b1_xy - b1_wh_half\n",
        "    b1_maxes = b1_xy + b1_wh_half\n",
        "\n",
        "    # Expand dim to apply broadcasting.\n",
        "    b2 = K.expand_dims(b2, 0)\n",
        "    b2_xy = b2[..., :2]\n",
        "    b2_wh = b2[..., 2:4]\n",
        "    b2_wh_half = b2_wh / 2.\n",
        "    b2_mins = b2_xy - b2_wh_half\n",
        "    b2_maxes = b2_xy + b2_wh_half\n",
        "\n",
        "    intersect_mins = K.maximum(b1_mins, b2_mins)\n",
        "    intersect_maxes = K.minimum(b1_maxes, b2_maxes)\n",
        "    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "    b1_area = b1_wh[..., 0] * b1_wh[..., 1]\n",
        "    b2_area = b2_wh[..., 0] * b2_wh[..., 1]\n",
        "    iou = intersect_area / (b1_area + b2_area - intersect_area)\n",
        "    all_ious.append(iou)\n",
        "    return iou\n",
        "\n",
        "\n",
        "def box_diou(b1, b2):\n",
        "    b1_xy = b1[..., :2]\n",
        "    b1_wh = b1[..., 2:4]\n",
        "    b1_wh_half = b1_wh / 2.\n",
        "    b1_mins = b1_xy - b1_wh_half\n",
        "    b1_maxes = b1_xy + b1_wh_half\n",
        "\n",
        "    b2_xy = b2[..., :2]\n",
        "    b2_wh = b2[..., 2:4]\n",
        "    b2_wh_half = b2_wh / 2.\n",
        "    b2_mins = b2_xy - b2_wh_half\n",
        "    b2_maxes = b2_xy + b2_wh_half\n",
        "\n",
        "    intersect_mins = K.maximum(b1_mins, b2_mins)\n",
        "    intersect_maxes = K.minimum(b1_maxes, b2_maxes)\n",
        "    intersect_wh = K.maximum(intersect_maxes - intersect_mins, 0.)\n",
        "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "    b1_area = b1_wh[..., 0] * b1_wh[..., 1]\n",
        "    b2_area = b2_wh[..., 0] * b2_wh[..., 1]\n",
        "    union_area = b1_area + b2_area - intersect_area\n",
        "    iou = intersect_area / (union_area + K.epsilon())\n",
        "\n",
        "    center_distance = K.sum(K.square(b1_xy - b2_xy), axis=-1)\n",
        "    enclose_mins = K.minimum(b1_mins, b2_mins)\n",
        "    enclose_maxes = K.maximum(b1_maxes, b2_maxes)\n",
        "    enclose_wh = K.maximum(enclose_maxes - enclose_mins, 0.0)\n",
        "    enclose_diagonal = K.sum(K.square(enclose_wh), axis=-1)\n",
        "    diou = iou - 1.0 * (center_distance) / (enclose_diagonal + K.epsilon())\n",
        "\n",
        "    diou = K.expand_dims(diou, -1)\n",
        "    return diou\n",
        "\n",
        "\n",
        "def yolo_loss(args, anchors, num_classes, ignore_thresh=.5):\n",
        "    \"\"\"Return yolo_loss tensor\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    yolo_outputs: list of tensor, the output of yolo_body or tiny_yolo_body\n",
        "    y_true: list of array, the output of preprocess_true_boxes\n",
        "    anchors: array, shape=(N, 2), wh\n",
        "    num_classes: integer\n",
        "    ignore_thresh: float, the iou threshold whether to ignore object confidence loss\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    loss: tensor, shape=(1,)\n",
        "\n",
        "    \"\"\"\n",
        "    num_layers = 1\n",
        "    yolo_outputs = args[:num_layers]\n",
        "    y_true = args[num_layers:]\n",
        "    g_y_true = y_true\n",
        "    input_shape = K.cast(K.shape(yolo_outputs[0])[1:3] * grid_size_multiplier, K.dtype(y_true[0]))\n",
        "    grid_shapes = [K.cast(K.shape(yolo_outputs[l])[1:3], K.dtype(y_true[0])) for l in range(num_layers)]\n",
        "    loss = 0\n",
        "\n",
        "    m = K.shape(yolo_outputs[0])[0]  # batch size, tensor\n",
        "    mf = K.cast(m, K.dtype(yolo_outputs[0]))\n",
        "    for layer in range(num_layers):\n",
        "        object_mask = y_true[layer][..., 4:5]\n",
        "        vertices_mask = y_true[layer][..., 5 + num_classes + 2:5 + num_classes + NUM_ANGLES3:3]\n",
        "        true_class_probs = y_true[layer][..., 5:5 + num_classes]\n",
        "\n",
        "        grid, raw_pred, pred_xy, pred_wh, pol_cnf = yolo_head(yolo_outputs[layer], anchors[anchor_mask[layer]], num_classes, input_shape, calc_loss=True)\n",
        "        pred_box = K.concatenate([pred_xy, pred_wh])\n",
        "        raw_true_xy = y_true[layer][..., :2] * grid_shapes[layer][::-1] - grid\n",
        "        raw_true_polygon0 = y_true[layer][..., 5 + num_classes: 5 + num_classes + NUM_ANGLES3]\n",
        "\n",
        "        raw_true_wh = K.log(y_true[layer][..., 2:4] / anchors[anchor_mask[layer]] * input_shape[::-1])\n",
        "        raw_true_wh = K.switch(object_mask, raw_true_wh, K.zeros_like(raw_true_wh))  # avoid log(0)=-inf\n",
        "\n",
        "        raw_true_polygon_x = raw_true_polygon0[..., ::3]\n",
        "        raw_true_polygon_y = raw_true_polygon0[..., 1::3]\n",
        "\n",
        "        dx = K.square(anchors[anchor_mask[layer]][..., 0:1] / 2)\n",
        "        dy = K.square(anchors[anchor_mask[layer]][..., 1:2] / 2)\n",
        "        d = K.cast(K.sqrt(dx + dy), K.dtype(raw_true_polygon_x))\n",
        "\n",
        "        diagonal = K.sqrt(K.pow(input_shape[::-1][0], 2) + K.pow(input_shape[::-1][1], 2))\n",
        "        raw_true_polygon_x = K.log(raw_true_polygon_x / d * diagonal)\n",
        "        raw_true_polygon_x = K.switch(vertices_mask, raw_true_polygon_x, K.zeros_like(raw_true_polygon_x))\n",
        "        box_loss_scale = 2 - y_true[layer][..., 2:3] * y_true[layer][..., 3:4]\n",
        "\n",
        "        # Find ignore mask, iterate over each of batch.\n",
        "        ignore_mask = tf.TensorArray(K.dtype(y_true[0]), size=1, dynamic_size=True)\n",
        "        object_mask_bool = K.cast(object_mask, 'bool')\n",
        "\n",
        "        def loop_body(b, ignore_mask):\n",
        "            true_box = tf.boolean_mask(y_true[layer][b, ..., 0:4], object_mask_bool[b, ..., 0])\n",
        "            iou = box_iou(pred_box[b], true_box)\n",
        "            best_iou = K.max(iou, axis=-1)\n",
        "            ignore_mask = ignore_mask.write(b, K.cast(best_iou < ignore_thresh, K.dtype(true_box)))\n",
        "            return b + 1, ignore_mask\n",
        "\n",
        "        _, ignore_mask = tf.while_loop(lambda b, *args: b < m, loop_body, [0, ignore_mask])\n",
        "        ignore_mask = ignore_mask.stack()\n",
        "        ignore_mask = K.expand_dims(ignore_mask, -1)\n",
        "\n",
        "        # K.binary_crossentropy is helpful to avoid exp overflow.\n",
        "        xy_loss = object_mask * box_loss_scale * K.binary_crossentropy(raw_true_xy, raw_pred[..., 0:2], from_logits=True)\n",
        "        wh_loss = object_mask * box_loss_scale * 0.5 * K.square(raw_true_wh - raw_pred[..., 2:4])\n",
        "        confidence_loss = object_mask * K.binary_crossentropy(object_mask, raw_pred[..., 4:5], from_logits=True) + (1 - object_mask) * K.binary_crossentropy(object_mask, raw_pred[..., 4:5],\n",
        "                                                                                                                                                             from_logits=True) * ignore_mask\n",
        "        class_loss = object_mask * K.binary_crossentropy(true_class_probs, raw_pred[..., 5:5 + num_classes], from_logits=True)\n",
        "        polygon_loss_x = object_mask * vertices_mask * box_loss_scale * 0.5 * K.square(raw_true_polygon_x - raw_pred[..., 5 + num_classes:5 + num_classes + NUM_ANGLES3:3])\n",
        "        polygon_loss_y = object_mask * vertices_mask * box_loss_scale * K.binary_crossentropy(raw_true_polygon_y, raw_pred[..., 5 + num_classes + 1:5 + num_classes + NUM_ANGLES3:3], from_logits=True)\n",
        "        vertices_confidence_loss = object_mask * K.binary_crossentropy(vertices_mask, raw_pred[..., 5 + num_classes + 2:5 + num_classes + NUM_ANGLES3:3], from_logits=True)\n",
        "\n",
        "        xy_loss = K.sum(xy_loss) / mf\n",
        "        wh_loss = K.sum(wh_loss) / mf\n",
        "        class_loss = K.sum(class_loss) / mf\n",
        "        confidence_loss = K.sum(confidence_loss) / mf\n",
        "        vertices_confidence_loss = K.sum(vertices_confidence_loss) / mf\n",
        "        polygon_loss = K.sum(polygon_loss_x) / mf + K.sum(polygon_loss_y) / mf\n",
        "\n",
        "        diou_loss = K.sum(object_mask * box_loss_scale * (1 - box_diou(pred_box, y_true[layer][..., 0:4]))) / mf\n",
        "\n",
        "        loss += (xy_loss + wh_loss + confidence_loss + class_loss + 0.2 * polygon_loss + 0.2 * vertices_confidence_loss)/ (K.sum(object_mask) + 1)*mf\n",
        "    all_losses.append(loss)\n",
        "    return loss\n",
        "\n",
        "\n",
        "class YOLO(object):\n",
        "    _defaults = {\n",
        "        \"model_path\": 'model_data/yolo.h5',\n",
        "        \"anchors_path\": 'yolo_anchors.txt',\n",
        "        \"classes_path\": 'yolo_classes.txt',\n",
        "        \"score\": 0.2,\n",
        "        \"iou\": 0.4,\n",
        "        \"model_image_size\": (416,832),\n",
        "        \"gpu_num\": 1,\n",
        "    }\n",
        "\n",
        "    @classmethod\n",
        "    def get_defaults(cls, n):\n",
        "        if n in cls._defaults:\n",
        "            return cls._defaults[n]\n",
        "        else:\n",
        "            return \"Unrecognized attribute name '\" + n + \"'\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        self.__dict__.update(self._defaults)  # set up default values\n",
        "        self.__dict__.update(kwargs)  # and update with user overrides\n",
        "        self.class_names = self._get_class()\n",
        "        self.anchors = self._get_anchors()\n",
        "        self.sess = K.get_session()\n",
        "        self.boxes, self.scores, self.classes, self.polygons = self.generate()\n",
        "\n",
        "    def _get_class(self):\n",
        "        classes_path = os.path.expanduser(self.classes_path)\n",
        "        with open(classes_path) as f:\n",
        "            class_names = f.readlines()\n",
        "        class_names = [c.strip() for c in class_names]\n",
        "        return class_names\n",
        "\n",
        "    def _get_anchors(self):\n",
        "        anchors_path = os.path.expanduser(self.anchors_path)\n",
        "        with open(anchors_path) as f:\n",
        "            anchors = f.readline()\n",
        "        anchors = [float(x) for x in anchors.split(',')]\n",
        "        return np.array(anchors).reshape(-1, 2)\n",
        "\n",
        "    def generate(self):\n",
        "        model_path = os.path.expanduser(self.model_path)\n",
        "        assert model_path.endswith('.h5'), 'Keras model or weights must be a .h5 file.'\n",
        "\n",
        "        # Load model, or construct model and load weights.\n",
        "        num_anchors = len(self.anchors)\n",
        "        num_classes = len(self.class_names)\n",
        "        try:\n",
        "            self.yolo_model = load_model(model_path, compile=False)\n",
        "        except:\n",
        "            self.yolo_model = yolo_body(Input(shape=(None, None, 3)), anchors_per_level, num_classes)\n",
        "            self.yolo_model.load_weights(self.model_path)  # make sure model, anchors and classes match\n",
        "        else:\n",
        "            # novy output\n",
        "            assert self.yolo_model.layers[-1].output_shape[-1] == \\\n",
        "                   num_anchors / len(self.yolo_model.output) * (num_classes + 5 + NUM_ANGLES3), \\\n",
        "                'Mismatch between model and given anchor and class sizes'\n",
        "\n",
        "        print('{} model, anchors, and classes loaded.'.format(model_path))\n",
        "\n",
        "        # Generate output tensor targets for filtered bounding boxes.\n",
        "        self.input_image_shape = K.placeholder(shape=(2,))\n",
        "        if self.gpu_num >= 2:\n",
        "            self.yolo_model = multi_gpu_model(self.yolo_model, gpus=self.gpu_num)\n",
        "        boxes, scores, classes, polygons = yolo_eval(self.yolo_model.output, self.anchors,\n",
        "                                                     len(self.class_names), self.input_image_shape,\n",
        "                                                     score_threshold=self.score, iou_threshold=self.iou)\n",
        "        return boxes, scores, classes, polygons\n",
        "\n",
        "    def detect_image(self, image):\n",
        "        if self.model_image_size != (None, None):\n",
        "            assert self.model_image_size[0] % 32 == 0, 'Multiples of 32 required'\n",
        "            assert self.model_image_size[1] % 32 == 0, 'Multiples of 32 required'\n",
        "            boxed_image = letterbox_image(image, tuple(reversed(self.model_image_size)))\n",
        "        else:\n",
        "            print('THE functionality is not implemented!')\n",
        "\n",
        "\n",
        "        image_data = np.expand_dims(boxed_image, 0)  # Add batch dimension.\n",
        "        out_boxes, out_scores, out_classes, polygons = self.sess.run(\n",
        "            [self.boxes, self.scores, self.classes, self.polygons],\n",
        "            feed_dict={\n",
        "                self.yolo_model.input: image_data,\n",
        "                self.input_image_shape: [image.shape[0], image.shape[1]],\n",
        "                K.learning_phase(): 0\n",
        "            })\n",
        "\n",
        "\n",
        "\n",
        "        for b in range(0, out_boxes.shape[0]):\n",
        "            cy = (out_boxes[b, 0] + out_boxes[b, 2]) // 2\n",
        "            cx = (out_boxes[b, 1] + out_boxes[b, 3]) // 2\n",
        "            diagonal = np.sqrt(np.power(out_boxes[b, 3] - out_boxes[b, 1], 2.0) + np.power(out_boxes[b, 2] - out_boxes[b, 0], 2.0))\n",
        "            for i in range(0, NUM_ANGLES):\n",
        "                x1 = cx - math.cos(math.radians((polygons[b, i+NUM_ANGLES] + i) / NUM_ANGLES * 360)) * polygons[b, i] *diagonal# scale[1]\n",
        "                y1 = cy - math.sin(math.radians((polygons[b, i+NUM_ANGLES] + i) / NUM_ANGLES * 360)) * polygons[b, i] *diagonal# scale[0]\n",
        "                polygons[b, i]            = x1\n",
        "                polygons[b, i+NUM_ANGLES] = y1\n",
        "\n",
        "        return out_boxes, out_scores, out_classes, polygons\n",
        "\n",
        "    def close_session(self):\n",
        "        self.sess.close()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    \"\"\"\n",
        "    Retrain the YOLO model for your own dataset.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    def _main():\n",
        "        phase = 1\n",
        "\n",
        "        annotation_path = '/content/poly-yolo/poly_yolo/train/_annotations.txt'\n",
        "        validation_path = '/content/poly-yolo/poly_yolo/valid/_annotations.txt'\n",
        "        log_dir = '/content/poly-yolo/poly_yolo/models'\n",
        "        classes_path = '/content/poly-yolo/yolo_classes.txt'\n",
        "        anchors_path = '/content/poly-yolo/yolo_anchors.txt'\n",
        "        class_names = get_classes(classes_path)\n",
        "        num_classes = len(class_names)\n",
        "        anchors = get_anchors(anchors_path)\n",
        "\n",
        "        input_shape = (416,832) # multiple of 32, hw\n",
        "\n",
        "        if phase == 1:\n",
        "            model = create_model(input_shape, anchors, num_classes, load_pretrained=False)\n",
        "        else:\n",
        "            model = create_model(input_shape, anchors, num_classes, load_pretrained=True, weights_path=log_dir+'poly_yolo.h5')\n",
        "\n",
        "        print(model.summary())\n",
        "\n",
        "        checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
        "                                     monitor='val_loss', save_weights_only=True, save_best_only=True, period=1, verbose=1)\n",
        "        reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1, delta=0.03)\n",
        "        early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)\n",
        "\n",
        "        with open(annotation_path) as f:\n",
        "            lines = f.readlines()\n",
        "\n",
        "        with open(validation_path) as f:\n",
        "            lines_val = f.readlines()\n",
        "\n",
        "        for i in range (0, len(lines)):\n",
        "            lines[i] = lines[i].split()\n",
        "            for element in range(1, len(lines[i])):\n",
        "                for symbol in range(lines[i][element].count(',') - 4, MAX_VERTICES * 2, 2):\n",
        "                    lines[i][element] = lines[i][element] + ',0,0'\n",
        "\n",
        "        for i in range(0, len(lines_val)):\n",
        "            lines_val[i] = lines_val[i].split()\n",
        "            for element in range(1, len(lines_val[i])):\n",
        "                for symbol in range(lines_val[i][element].count(',') - 4, MAX_VERTICES * 2, 2):\n",
        "                    lines_val[i][element] = lines_val[i][element] + ',0,0'\n",
        "\n",
        "        num_val = int(len(lines_val))\n",
        "        num_train = len(lines)\n",
        "\n",
        "\n",
        "        batch_size = 3 # decrease/increase batch size according to your memory of your GPU\n",
        "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
        "\n",
        "\n",
        "\n",
        "        model.compile(optimizer=Adadelta(1.0), loss={'yolo_loss': lambda y_true, y_pred: y_pred})\n",
        "        epochs = 10\n",
        "        model.fit_generator(\n",
        "            data_generator_wrapper(lines, batch_size, input_shape, anchors, num_classes, True),\n",
        "                  steps_per_epoch=max(1, num_train // batch_size),\n",
        "                  validation_data=data_generator_wrapper(lines_val, batch_size, input_shape, anchors, num_classes, False),\n",
        "                  validation_steps=max(1, num_val // batch_size),\n",
        "                  epochs=epochs,\n",
        "                  initial_epoch=0,\n",
        "                  callbacks=[reduce_lr, early_stopping, checkpoint])\n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "    def get_classes(classes_path):\n",
        "        \"\"\"loads the classes\"\"\"\n",
        "        with open(classes_path) as f:\n",
        "            class_names = f.readlines()\n",
        "        class_names = [c.strip() for c in class_names]\n",
        "        return class_names\n",
        "\n",
        "\n",
        "    def get_anchors(anchors_path):\n",
        "        \"\"\"loads the anchors from a file\"\"\"\n",
        "        with open(anchors_path) as f:\n",
        "            anchors = f.readline()\n",
        "        anchors = [float(x) for x in anchors.split(',')]\n",
        "        return np.array(anchors).reshape(-1, 2)\n",
        "\n",
        "\n",
        "    def create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
        "                     weights_path='model_data/yolo_weights.h5'):\n",
        "        \"\"\"create the training model\"\"\"\n",
        "        K.clear_session()  # get a new session\n",
        "        image_input = Input(shape=(None, None, 3))\n",
        "        h, w = input_shape\n",
        "        num_anchors = len(anchors)\n",
        "        y_true = Input(shape=(h // grid_size_multiplier, w // grid_size_multiplier, anchors_per_level, num_classes + 5 + NUM_ANGLES3))\n",
        "\n",
        "        model_body = yolo_body(image_input, anchors_per_level, num_classes)\n",
        "        print('Create Poly-YOLO model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
        "\n",
        "        if load_pretrained:\n",
        "            model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
        "            print('Load weights {}.'.format(weights_path))\n",
        "\n",
        "        model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
        "                            arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
        "            [model_body.output, y_true])\n",
        "        model = Model([model_body.input, y_true], model_loss)\n",
        "\n",
        "        # print(model.summary())\n",
        "        return model\n",
        "\n",
        "\n",
        "    def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes, is_random):\n",
        "        \"\"\"data generator for fit_generator\"\"\"\n",
        "        n = len(annotation_lines)\n",
        "        i = 0\n",
        "        while True:\n",
        "            image_data = []\n",
        "            box_data = []\n",
        "            for b in range(batch_size):\n",
        "                if i == 0:\n",
        "                    np.random.shuffle(annotation_lines)\n",
        "                try:\n",
        "                  image, box = get_random_data(annotation_lines[i], input_shape, random=is_random)\n",
        "                except:\n",
        "                  image, box = get_random_data(annotation_lines[0], input_shape, random=is_random)\n",
        "                image_data.append(image)\n",
        "                box_data.append(box)\n",
        "                i = (i + 1) % n\n",
        "            image_data = np.array(image_data)\n",
        "            box_data = np.array(box_data)\n",
        "            y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
        "            yield [image_data, *y_true], np.zeros(batch_size)\n",
        "\n",
        "\n",
        "    def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes, random):\n",
        "        n = len(annotation_lines)\n",
        "        if n == 0 or batch_size <= 0: return None\n",
        "        return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes, random)\n",
        "    if __name__ == '__main__':\n",
        "        _main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lpbwwZJErC4l",
        "outputId": "adb5b758-f9d0-4b6a-b60f-f897437b0c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create Poly-YOLO model with 9 anchors and 13 classes.\n",
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, None, None, 2 648         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, None, None, 2 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)       (None, None, None, 2 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_1 (ZeroPadding2D (None, None, None, 2 0           leaky_re_lu_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, None, None, 4 10368       zero_padding2d_1[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, None, None, 4 192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)       (None, None, None, 4 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, None, None, 2 1152        leaky_re_lu_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, None, None, 2 96          conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)       (None, None, None, 2 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, None, None, 4 10368       leaky_re_lu_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, None, None, 4 192         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, None, None, 4 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 48)           0           leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 1, 1, 48)     0           global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1, 1, 3)      144         reshape_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)       (None, 1, 1, 3)      0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 1, 1, 48)     144         leaky_re_lu_5[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply_1 (Multiply)           (None, None, None, 4 0           leaky_re_lu_4[0][0]              \n",
            "                                                                 dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, None, None, 4 0           leaky_re_lu_2[0][0]              \n",
            "                                                                 multiply_1[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPadding2D (None, None, None, 4 0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, None, None, 9 41472       zero_padding2d_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, None, None, 9 384         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)       (None, None, None, 9 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, None, None, 4 4608        leaky_re_lu_6[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, None, None, 4 192         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)       (None, None, None, 4 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, None, None, 9 41472       leaky_re_lu_7[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, None, None, 9 384         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)       (None, None, None, 9 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_2 (Glo (None, 96)           0           leaky_re_lu_8[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 1, 1, 96)     0           global_average_pooling2d_2[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1, 1, 6)      576         reshape_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)       (None, 1, 1, 6)      0           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 1, 1, 96)     576         leaky_re_lu_9[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "multiply_2 (Multiply)           (None, None, None, 9 0           leaky_re_lu_8[0][0]              \n",
            "                                                                 dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, None, None, 9 0           leaky_re_lu_6[0][0]              \n",
            "                                                                 multiply_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, None, None, 4 4608        add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, None, None, 4 192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, None, None, 4 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, None, None, 9 41472       leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, None, None, 9 384         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, None, None, 9 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_3 (Glo (None, 96)           0           leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 1, 1, 96)     0           global_average_pooling2d_3[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 1, 1, 6)      576         reshape_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)      (None, 1, 1, 6)      0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1, 1, 96)     576         leaky_re_lu_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_3 (Multiply)           (None, None, None, 9 0           leaky_re_lu_11[0][0]             \n",
            "                                                                 dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, None, None, 9 0           add_2[0][0]                      \n",
            "                                                                 multiply_3[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPadding2D (None, None, None, 9 0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, None, None, 1 165888      zero_padding2d_3[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, None, None, 1 768         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, None, None, 9 18432       leaky_re_lu_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, None, None, 9 384         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)      (None, None, None, 9 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, None, None, 1 165888      leaky_re_lu_14[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, None, None, 1 768         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_15 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_4 (Glo (None, 192)          0           leaky_re_lu_15[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_4 (Reshape)             (None, 1, 1, 192)    0           global_average_pooling2d_4[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 1, 1, 12)     2304        reshape_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_16 (LeakyReLU)      (None, 1, 1, 12)     0           dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 1, 1, 192)    2304        leaky_re_lu_16[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_4 (Multiply)           (None, None, None, 1 0           leaky_re_lu_15[0][0]             \n",
            "                                                                 dense_8[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, None, None, 1 0           leaky_re_lu_13[0][0]             \n",
            "                                                                 multiply_4[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, None, None, 9 18432       add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, None, None, 9 384         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_17 (LeakyReLU)      (None, None, None, 9 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, None, None, 1 165888      leaky_re_lu_17[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, None, None, 1 768         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_18 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_5 (Glo (None, 192)          0           leaky_re_lu_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_5 (Reshape)             (None, 1, 1, 192)    0           global_average_pooling2d_5[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 1, 1, 12)     2304        reshape_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_19 (LeakyReLU)      (None, 1, 1, 12)     0           dense_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 1, 1, 192)    2304        leaky_re_lu_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_5 (Multiply)           (None, None, None, 1 0           leaky_re_lu_18[0][0]             \n",
            "                                                                 dense_10[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, None, None, 1 0           add_4[0][0]                      \n",
            "                                                                 multiply_5[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, None, None, 9 18432       add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, None, None, 9 384         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_20 (LeakyReLU)      (None, None, None, 9 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, None, None, 1 165888      leaky_re_lu_20[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, None, None, 1 768         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_21 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_6 (Glo (None, 192)          0           leaky_re_lu_21[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_6 (Reshape)             (None, 1, 1, 192)    0           global_average_pooling2d_6[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_11 (Dense)                (None, 1, 1, 12)     2304        reshape_6[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_22 (LeakyReLU)      (None, 1, 1, 12)     0           dense_11[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_12 (Dense)                (None, 1, 1, 192)    2304        leaky_re_lu_22[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_6 (Multiply)           (None, None, None, 1 0           leaky_re_lu_21[0][0]             \n",
            "                                                                 dense_12[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, None, None, 1 0           add_5[0][0]                      \n",
            "                                                                 multiply_6[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, None, None, 9 18432       add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, None, None, 9 384         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_23 (LeakyReLU)      (None, None, None, 9 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, None, None, 1 165888      leaky_re_lu_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, None, None, 1 768         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_24 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_7 (Glo (None, 192)          0           leaky_re_lu_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_7 (Reshape)             (None, 1, 1, 192)    0           global_average_pooling2d_7[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_13 (Dense)                (None, 1, 1, 12)     2304        reshape_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_25 (LeakyReLU)      (None, 1, 1, 12)     0           dense_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 1, 1, 192)    2304        leaky_re_lu_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_7 (Multiply)           (None, None, None, 1 0           leaky_re_lu_24[0][0]             \n",
            "                                                                 dense_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, None, None, 1 0           add_6[0][0]                      \n",
            "                                                                 multiply_7[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, None, None, 9 18432       add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, None, None, 9 384         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_26 (LeakyReLU)      (None, None, None, 9 0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, None, None, 1 165888      leaky_re_lu_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, None, None, 1 768         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_27 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_8 (Glo (None, 192)          0           leaky_re_lu_27[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_8 (Reshape)             (None, 1, 1, 192)    0           global_average_pooling2d_8[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 1, 1, 12)     2304        reshape_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_28 (LeakyReLU)      (None, 1, 1, 12)     0           dense_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 1, 1, 192)    2304        leaky_re_lu_28[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_8 (Multiply)           (None, None, None, 1 0           leaky_re_lu_27[0][0]             \n",
            "                                                                 dense_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, None, None, 1 0           add_7[0][0]                      \n",
            "                                                                 multiply_8[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, None, None, 9 18432       add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, None, None, 9 384         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_29 (LeakyReLU)      (None, None, None, 9 0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, None, None, 1 165888      leaky_re_lu_29[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, None, None, 1 768         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_30 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_9 (Glo (None, 192)          0           leaky_re_lu_30[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_9 (Reshape)             (None, 1, 1, 192)    0           global_average_pooling2d_9[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 1, 1, 12)     2304        reshape_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_31 (LeakyReLU)      (None, 1, 1, 12)     0           dense_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 1, 1, 192)    2304        leaky_re_lu_31[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_9 (Multiply)           (None, None, None, 1 0           leaky_re_lu_30[0][0]             \n",
            "                                                                 dense_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, None, None, 1 0           add_8[0][0]                      \n",
            "                                                                 multiply_9[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, None, None, 9 18432       add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, None, None, 9 384         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_32 (LeakyReLU)      (None, None, None, 9 0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, None, None, 1 165888      leaky_re_lu_32[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, None, None, 1 768         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_33 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_10 (Gl (None, 192)          0           leaky_re_lu_33[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_10 (Reshape)            (None, 1, 1, 192)    0           global_average_pooling2d_10[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_19 (Dense)                (None, 1, 1, 12)     2304        reshape_10[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_34 (LeakyReLU)      (None, 1, 1, 12)     0           dense_19[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_20 (Dense)                (None, 1, 1, 192)    2304        leaky_re_lu_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_10 (Multiply)          (None, None, None, 1 0           leaky_re_lu_33[0][0]             \n",
            "                                                                 dense_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, None, None, 1 0           add_9[0][0]                      \n",
            "                                                                 multiply_10[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, None, None, 9 18432       add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, None, None, 9 384         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_35 (LeakyReLU)      (None, None, None, 9 0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, None, None, 1 165888      leaky_re_lu_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, None, None, 1 768         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_36 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_11 (Gl (None, 192)          0           leaky_re_lu_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_11 (Reshape)            (None, 1, 1, 192)    0           global_average_pooling2d_11[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_21 (Dense)                (None, 1, 1, 12)     2304        reshape_11[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_37 (LeakyReLU)      (None, 1, 1, 12)     0           dense_21[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_22 (Dense)                (None, 1, 1, 192)    2304        leaky_re_lu_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_11 (Multiply)          (None, None, None, 1 0           leaky_re_lu_36[0][0]             \n",
            "                                                                 dense_22[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, None, None, 1 0           add_10[0][0]                     \n",
            "                                                                 multiply_11[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPadding2D (None, None, None, 1 0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, None, None, 3 663552      zero_padding2d_4[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, None, None, 3 1536        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_38 (LeakyReLU)      (None, None, None, 3 0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, None, None, 1 73728       leaky_re_lu_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, None, None, 1 768         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_39 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, None, None, 3 663552      leaky_re_lu_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, None, None, 3 1536        conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_40 (LeakyReLU)      (None, None, None, 3 0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_12 (Gl (None, 384)          0           leaky_re_lu_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_12 (Reshape)            (None, 1, 1, 384)    0           global_average_pooling2d_12[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_23 (Dense)                (None, 1, 1, 24)     9216        reshape_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_41 (LeakyReLU)      (None, 1, 1, 24)     0           dense_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_24 (Dense)                (None, 1, 1, 384)    9216        leaky_re_lu_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_12 (Multiply)          (None, None, None, 3 0           leaky_re_lu_40[0][0]             \n",
            "                                                                 dense_24[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, None, None, 3 0           leaky_re_lu_38[0][0]             \n",
            "                                                                 multiply_12[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, None, None, 1 73728       add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, None, None, 1 768         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_42 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, None, None, 3 663552      leaky_re_lu_42[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, None, None, 3 1536        conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_43 (LeakyReLU)      (None, None, None, 3 0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_13 (Gl (None, 384)          0           leaky_re_lu_43[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_13 (Reshape)            (None, 1, 1, 384)    0           global_average_pooling2d_13[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_25 (Dense)                (None, 1, 1, 24)     9216        reshape_13[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_44 (LeakyReLU)      (None, 1, 1, 24)     0           dense_25[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_26 (Dense)                (None, 1, 1, 384)    9216        leaky_re_lu_44[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_13 (Multiply)          (None, None, None, 3 0           leaky_re_lu_43[0][0]             \n",
            "                                                                 dense_26[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, None, None, 3 0           add_12[0][0]                     \n",
            "                                                                 multiply_13[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, None, None, 1 73728       add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, None, None, 1 768         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_45 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, None, None, 3 663552      leaky_re_lu_45[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, None, None, 3 1536        conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_46 (LeakyReLU)      (None, None, None, 3 0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_14 (Gl (None, 384)          0           leaky_re_lu_46[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_14 (Reshape)            (None, 1, 1, 384)    0           global_average_pooling2d_14[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_27 (Dense)                (None, 1, 1, 24)     9216        reshape_14[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_47 (LeakyReLU)      (None, 1, 1, 24)     0           dense_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_28 (Dense)                (None, 1, 1, 384)    9216        leaky_re_lu_47[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_14 (Multiply)          (None, None, None, 3 0           leaky_re_lu_46[0][0]             \n",
            "                                                                 dense_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, None, None, 3 0           add_13[0][0]                     \n",
            "                                                                 multiply_14[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, None, None, 1 73728       add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, None, None, 1 768         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_48 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, None, None, 3 663552      leaky_re_lu_48[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, None, None, 3 1536        conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_49 (LeakyReLU)      (None, None, None, 3 0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_15 (Gl (None, 384)          0           leaky_re_lu_49[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_15 (Reshape)            (None, 1, 1, 384)    0           global_average_pooling2d_15[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_29 (Dense)                (None, 1, 1, 24)     9216        reshape_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_50 (LeakyReLU)      (None, 1, 1, 24)     0           dense_29[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_30 (Dense)                (None, 1, 1, 384)    9216        leaky_re_lu_50[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_15 (Multiply)          (None, None, None, 3 0           leaky_re_lu_49[0][0]             \n",
            "                                                                 dense_30[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, None, None, 3 0           add_14[0][0]                     \n",
            "                                                                 multiply_15[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, None, None, 1 73728       add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, None, None, 1 768         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_51 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, None, None, 3 663552      leaky_re_lu_51[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, None, None, 3 1536        conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_52 (LeakyReLU)      (None, None, None, 3 0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_16 (Gl (None, 384)          0           leaky_re_lu_52[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_16 (Reshape)            (None, 1, 1, 384)    0           global_average_pooling2d_16[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_31 (Dense)                (None, 1, 1, 24)     9216        reshape_16[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_53 (LeakyReLU)      (None, 1, 1, 24)     0           dense_31[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_32 (Dense)                (None, 1, 1, 384)    9216        leaky_re_lu_53[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_16 (Multiply)          (None, None, None, 3 0           leaky_re_lu_52[0][0]             \n",
            "                                                                 dense_32[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_16 (Add)                    (None, None, None, 3 0           add_15[0][0]                     \n",
            "                                                                 multiply_16[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, None, None, 1 73728       add_16[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, None, None, 1 768         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_54 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, None, None, 3 663552      leaky_re_lu_54[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, None, None, 3 1536        conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_55 (LeakyReLU)      (None, None, None, 3 0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_17 (Gl (None, 384)          0           leaky_re_lu_55[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_17 (Reshape)            (None, 1, 1, 384)    0           global_average_pooling2d_17[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_33 (Dense)                (None, 1, 1, 24)     9216        reshape_17[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_56 (LeakyReLU)      (None, 1, 1, 24)     0           dense_33[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_34 (Dense)                (None, 1, 1, 384)    9216        leaky_re_lu_56[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_17 (Multiply)          (None, None, None, 3 0           leaky_re_lu_55[0][0]             \n",
            "                                                                 dense_34[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_17 (Add)                    (None, None, None, 3 0           add_16[0][0]                     \n",
            "                                                                 multiply_17[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, None, None, 1 73728       add_17[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, None, None, 1 768         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_57 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, None, None, 3 663552      leaky_re_lu_57[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, None, None, 3 1536        conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_58 (LeakyReLU)      (None, None, None, 3 0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_18 (Gl (None, 384)          0           leaky_re_lu_58[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_18 (Reshape)            (None, 1, 1, 384)    0           global_average_pooling2d_18[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_35 (Dense)                (None, 1, 1, 24)     9216        reshape_18[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_59 (LeakyReLU)      (None, 1, 1, 24)     0           dense_35[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_36 (Dense)                (None, 1, 1, 384)    9216        leaky_re_lu_59[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_18 (Multiply)          (None, None, None, 3 0           leaky_re_lu_58[0][0]             \n",
            "                                                                 dense_36[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_18 (Add)                    (None, None, None, 3 0           add_17[0][0]                     \n",
            "                                                                 multiply_18[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, None, None, 1 73728       add_18[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, None, None, 1 768         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_60 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, None, None, 3 663552      leaky_re_lu_60[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, None, None, 3 1536        conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_61 (LeakyReLU)      (None, None, None, 3 0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_19 (Gl (None, 384)          0           leaky_re_lu_61[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_19 (Reshape)            (None, 1, 1, 384)    0           global_average_pooling2d_19[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_37 (Dense)                (None, 1, 1, 24)     9216        reshape_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_62 (LeakyReLU)      (None, 1, 1, 24)     0           dense_37[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_38 (Dense)                (None, 1, 1, 384)    9216        leaky_re_lu_62[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_19 (Multiply)          (None, None, None, 3 0           leaky_re_lu_61[0][0]             \n",
            "                                                                 dense_38[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_19 (Add)                    (None, None, None, 3 0           add_18[0][0]                     \n",
            "                                                                 multiply_19[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPadding2D (None, None, None, 3 0           add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, None, None, 7 2654208     zero_padding2d_5[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, None, None, 7 3072        conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_63 (LeakyReLU)      (None, None, None, 7 0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, None, None, 3 294912      leaky_re_lu_63[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, None, None, 3 1536        conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_64 (LeakyReLU)      (None, None, None, 3 0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, None, None, 7 2654208     leaky_re_lu_64[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, None, None, 7 3072        conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_65 (LeakyReLU)      (None, None, None, 7 0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_20 (Gl (None, 768)          0           leaky_re_lu_65[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_20 (Reshape)            (None, 1, 1, 768)    0           global_average_pooling2d_20[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_39 (Dense)                (None, 1, 1, 48)     36864       reshape_20[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_66 (LeakyReLU)      (None, 1, 1, 48)     0           dense_39[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_40 (Dense)                (None, 1, 1, 768)    36864       leaky_re_lu_66[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_20 (Multiply)          (None, None, None, 7 0           leaky_re_lu_65[0][0]             \n",
            "                                                                 dense_40[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_20 (Add)                    (None, None, None, 7 0           leaky_re_lu_63[0][0]             \n",
            "                                                                 multiply_20[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, None, None, 3 294912      add_20[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, None, None, 3 1536        conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_67 (LeakyReLU)      (None, None, None, 3 0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, None, None, 7 2654208     leaky_re_lu_67[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, None, None, 7 3072        conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_68 (LeakyReLU)      (None, None, None, 7 0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_21 (Gl (None, 768)          0           leaky_re_lu_68[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_21 (Reshape)            (None, 1, 1, 768)    0           global_average_pooling2d_21[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_41 (Dense)                (None, 1, 1, 48)     36864       reshape_21[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_69 (LeakyReLU)      (None, 1, 1, 48)     0           dense_41[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_42 (Dense)                (None, 1, 1, 768)    36864       leaky_re_lu_69[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_21 (Multiply)          (None, None, None, 7 0           leaky_re_lu_68[0][0]             \n",
            "                                                                 dense_42[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_21 (Add)                    (None, None, None, 7 0           add_20[0][0]                     \n",
            "                                                                 multiply_21[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, None, None, 3 294912      add_21[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, None, None, 3 1536        conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_70 (LeakyReLU)      (None, None, None, 3 0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, None, None, 7 2654208     leaky_re_lu_70[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, None, None, 7 3072        conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_71 (LeakyReLU)      (None, None, None, 7 0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_22 (Gl (None, 768)          0           leaky_re_lu_71[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_22 (Reshape)            (None, 1, 1, 768)    0           global_average_pooling2d_22[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_43 (Dense)                (None, 1, 1, 48)     36864       reshape_22[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_72 (LeakyReLU)      (None, 1, 1, 48)     0           dense_43[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_44 (Dense)                (None, 1, 1, 768)    36864       leaky_re_lu_72[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_22 (Multiply)          (None, None, None, 7 0           leaky_re_lu_71[0][0]             \n",
            "                                                                 dense_44[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_22 (Add)                    (None, None, None, 7 0           add_21[0][0]                     \n",
            "                                                                 multiply_22[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, None, None, 3 294912      add_22[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, None, None, 3 1536        conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_73 (LeakyReLU)      (None, None, None, 3 0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, None, None, 7 2654208     leaky_re_lu_73[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, None, None, 7 3072        conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_74 (LeakyReLU)      (None, None, None, 7 0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_23 (Gl (None, 768)          0           leaky_re_lu_74[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_23 (Reshape)            (None, 1, 1, 768)    0           global_average_pooling2d_23[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_45 (Dense)                (None, 1, 1, 48)     36864       reshape_23[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_75 (LeakyReLU)      (None, 1, 1, 48)     0           dense_45[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_46 (Dense)                (None, 1, 1, 768)    36864       leaky_re_lu_75[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_23 (Multiply)          (None, None, None, 7 0           leaky_re_lu_74[0][0]             \n",
            "                                                                 dense_46[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_23 (Add)                    (None, None, None, 7 0           add_22[0][0]                     \n",
            "                                                                 multiply_23[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, None, None, 3 294912      add_23[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, None, None, 3 1536        conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_76 (LeakyReLU)      (None, None, None, 3 0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, None, None, 7 2654208     leaky_re_lu_76[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, None, None, 7 3072        conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_77 (LeakyReLU)      (None, None, None, 7 0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_24 (Gl (None, 768)          0           leaky_re_lu_77[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_24 (Reshape)            (None, 1, 1, 768)    0           global_average_pooling2d_24[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_47 (Dense)                (None, 1, 1, 48)     36864       reshape_24[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_78 (LeakyReLU)      (None, 1, 1, 48)     0           dense_47[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_48 (Dense)                (None, 1, 1, 768)    36864       leaky_re_lu_78[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_24 (Multiply)          (None, None, None, 7 0           leaky_re_lu_77[0][0]             \n",
            "                                                                 dense_48[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_24 (Add)                    (None, None, None, 7 0           add_23[0][0]                     \n",
            "                                                                 multiply_24[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, None, None, 3 294912      add_24[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, None, None, 3 1536        conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_79 (LeakyReLU)      (None, None, None, 3 0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, None, None, 7 2654208     leaky_re_lu_79[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, None, None, 7 3072        conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_80 (LeakyReLU)      (None, None, None, 7 0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_25 (Gl (None, 768)          0           leaky_re_lu_80[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_25 (Reshape)            (None, 1, 1, 768)    0           global_average_pooling2d_25[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_49 (Dense)                (None, 1, 1, 48)     36864       reshape_25[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_81 (LeakyReLU)      (None, 1, 1, 48)     0           dense_49[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_50 (Dense)                (None, 1, 1, 768)    36864       leaky_re_lu_81[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_25 (Multiply)          (None, None, None, 7 0           leaky_re_lu_80[0][0]             \n",
            "                                                                 dense_50[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_25 (Add)                    (None, None, None, 7 0           add_24[0][0]                     \n",
            "                                                                 multiply_25[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, None, None, 3 294912      add_25[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, None, None, 3 1536        conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_82 (LeakyReLU)      (None, None, None, 3 0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, None, None, 7 2654208     leaky_re_lu_82[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, None, None, 7 3072        conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_83 (LeakyReLU)      (None, None, None, 7 0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_26 (Gl (None, 768)          0           leaky_re_lu_83[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_26 (Reshape)            (None, 1, 1, 768)    0           global_average_pooling2d_26[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_51 (Dense)                (None, 1, 1, 48)     36864       reshape_26[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_84 (LeakyReLU)      (None, 1, 1, 48)     0           dense_51[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_52 (Dense)                (None, 1, 1, 768)    36864       leaky_re_lu_84[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_26 (Multiply)          (None, None, None, 7 0           leaky_re_lu_83[0][0]             \n",
            "                                                                 dense_52[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_26 (Add)                    (None, None, None, 7 0           add_25[0][0]                     \n",
            "                                                                 multiply_26[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, None, None, 3 294912      add_26[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, None, None, 3 1536        conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_85 (LeakyReLU)      (None, None, None, 3 0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, None, None, 7 2654208     leaky_re_lu_85[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, None, None, 7 3072        conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_86 (LeakyReLU)      (None, None, None, 7 0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_27 (Gl (None, 768)          0           leaky_re_lu_86[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "reshape_27 (Reshape)            (None, 1, 1, 768)    0           global_average_pooling2d_27[0][0]\n",
            "__________________________________________________________________________________________________\n",
            "dense_53 (Dense)                (None, 1, 1, 48)     36864       reshape_27[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_87 (LeakyReLU)      (None, 1, 1, 48)     0           dense_53[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_54 (Dense)                (None, 1, 1, 768)    36864       leaky_re_lu_87[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "multiply_27 (Multiply)          (None, None, None, 7 0           leaky_re_lu_86[0][0]             \n",
            "                                                                 dense_54[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_27 (Add)                    (None, None, None, 7 0           add_26[0][0]                     \n",
            "                                                                 multiply_27[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, None, None, 1 147456      add_27[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, None, None, 1 73728       add_19[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, None, None, 1 768         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, None, None, 1 768         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_91 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, None, None, 1 36864       add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_90 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, None, None, 1 0           leaky_re_lu_91[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, None, None, 1 768         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_28 (Add)                    (None, None, None, 1 0           leaky_re_lu_90[0][0]             \n",
            "                                                                 up_sampling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, None, None, 1 18432       add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_89 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, None, None, 1 0           add_28[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, None, None, 1 768         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_29 (Add)                    (None, None, None, 1 0           leaky_re_lu_89[0][0]             \n",
            "                                                                 up_sampling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_88 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_3 (UpSampling2D)  (None, None, None, 1 0           add_29[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "add_30 (Add)                    (None, None, None, 1 0           leaky_re_lu_88[0][0]             \n",
            "                                                                 up_sampling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, None, None, 1 36864       add_30[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, None, None, 1 768         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_92 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, None, None, 3 663552      leaky_re_lu_92[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, None, None, 3 1536        conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_93 (LeakyReLU)      (None, None, None, 3 0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, None, None, 1 73728       leaky_re_lu_93[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, None, None, 1 768         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_94 (LeakyReLU)      (None, None, None, 1 0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, None, None, 3 663552      leaky_re_lu_94[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, None, None, 3 1536        conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_95 (LeakyReLU)      (None, None, None, 3 0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, None, None, 8 311850      leaky_re_lu_95[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, 104, 208, 9,  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "yolo_loss (Lambda)              (None, 1)            0           conv2d_69[0][0]                  \n",
            "                                                                 input_2[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 37,488,018\n",
            "Trainable params: 37,448,178\n",
            "Non-trainable params: 39,840\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 163 samples, val on 15 samples, with batch size 3.\n",
            "Epoch 1/10\n",
            "53/54 [============================>.] - ETA: 1s - loss: 8983.4884"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-57dc8166eb82>\u001b[0m in \u001b[0;36mdata_generator\u001b[0;34m(annotation_lines, batch_size, input_shape, anchors, num_classes, is_random)\u001b[0m\n\u001b[1;32m   1033\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m                   \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_random_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_lines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_random\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-57dc8166eb82>\u001b[0m in \u001b[0;36mget_random_data\u001b[0;34m(line, input_shape, random, max_boxes, hue_alter, sat_alter, val_alter, proc_img)\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0miw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mih\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-57dc8166eb82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_lines\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manchors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m         \u001b[0m_main\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-18-57dc8166eb82>\u001b[0m in \u001b[0;36m_main\u001b[0;34m()\u001b[0m\n\u001b[1;32m    975\u001b[0m                   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m                   \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m                   callbacks=[reduce_lr, early_stopping, checkpoint])\n\u001b[0m\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(model, generator, steps, callbacks, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 719\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    720\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mworker\u001b[0;34m(inqueue, outqueue, initializer, initargs, maxtasks, wrap_exception)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mwrap_exception\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfunc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_helper_reraises_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mnext_sample\u001b[0;34m(uid)\u001b[0m\n",
            "\u001b[0;32m<ipython-input-18-57dc8166eb82>\u001b[0m in \u001b[0;36mdata_generator\u001b[0;34m(annotation_lines, batch_size, input_shape, anchors, num_classes, is_random)\u001b[0m\n\u001b[1;32m   1034\u001b[0m                   \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_random_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_lines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_random\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1036\u001b[0;31m                   \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_random_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotation_lines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_random\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1037\u001b[0m                 \u001b[0mimage_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                 \u001b[0mbox_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m_bounded_integers.pyx\u001b[0m in \u001b[0;36mnumpy.random._bounded_integers._rand_int64\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: high <= 0"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "print(all_losses)\n",
        "print(all_ious)\n",
        "for i in range(len(all_losses)):\n",
        "  all_losses[i] = (all_losses[i].numpy())[0]\n",
        "for i in range(len(all_ious)):\n",
        "  all_ious[i] = (all_ious[i].numpy())[0]\n",
        "plt.plot(np.arange(1, len(all_losses)+1, 1), np.array(all_losses), label='Loss vs iteration')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.plot(np.arange(1, len(all_ious)+1, 1), np.array(all_ious), label='IOU vs iteration')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "5qMDfztZK8rQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "!cp /content/poly-yolo/simulator_dataset/imgs/* /content/poly-yolo/poly_yolo/\n",
        "!cp /content/poly-yolo/simulator_dataset/simulator-train.txt train.txt\n",
        "!cp /content/poly-yolo/simulator_dataset/simulator-test.txt test.txt\n",
        "!cp /content/poly-yolo/simulator_dataset/simulator-val.txt val.txt\n",
        "!python3 poly_yolo_lite.py\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_QqwCuygC9q",
        "outputId": "6d780519-cc40-437b-f69b-8e7f894c1c6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "2022-03-22 17:55:41.909656: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
            "2022-03-22 17:55:41.929657: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-22 17:55:41.930398: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-03-22 17:55:41.930724: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-03-22 17:55:41.932680: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2022-03-22 17:55:41.933967: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2022-03-22 17:55:41.934356: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2022-03-22 17:55:41.936473: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-03-22 17:55:41.937590: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2022-03-22 17:55:41.941346: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-03-22 17:55:41.941448: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-22 17:55:41.942274: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-22 17:55:41.942944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2022-03-22 17:55:41.948604: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299995000 Hz\n",
            "2022-03-22 17:55:41.948809: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558c0ebf5640 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
            "2022-03-22 17:55:41.948843: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
            "2022-03-22 17:55:42.050035: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-22 17:55:42.050843: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x558c13066e00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "2022-03-22 17:55:42.050877: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla K80, Compute Capability 3.7\n",
            "2022-03-22 17:55:42.051072: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-22 17:55:42.051773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Found device 0 with properties: \n",
            "name: Tesla K80 major: 3 minor: 7 memoryClockRate(GHz): 0.8235\n",
            "pciBusID: 0000:00:04.0\n",
            "2022-03-22 17:55:42.051847: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-03-22 17:55:42.051896: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2022-03-22 17:55:42.051940: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n",
            "2022-03-22 17:55:42.051991: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n",
            "2022-03-22 17:55:42.052032: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n",
            "2022-03-22 17:55:42.052083: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n",
            "2022-03-22 17:55:42.052142: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "2022-03-22 17:55:42.052234: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-22 17:55:42.053010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-22 17:55:42.053753: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1767] Adding visible gpu devices: 0\n",
            "2022-03-22 17:55:42.053821: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "2022-03-22 17:55:42.055013: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1180] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
            "2022-03-22 17:55:42.055044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1186]      0 \n",
            "2022-03-22 17:55:42.055069: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1199] 0:   N \n",
            "2022-03-22 17:55:42.055199: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-22 17:55:42.055836: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2022-03-22 17:55:42.056453: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "2022-03-22 17:55:42.056532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1325] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10813 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7)\n",
            "Create Poly-YOLO model with 15 anchors and 13 classes.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:3170: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Train on 700 samples, val on 90 samples, with batch size 5.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.7/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "Epoch 1/100\n",
            "2022-03-22 17:56:25.592866: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n",
            "2022-03-22 17:56:26.404142: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
            "140/140 [==============================] - 114s 815ms/step - loss: 2833.3435 - val_loss: 763.0707\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 763.07068, saving model to models/ep001-loss2833.343-val_loss763.071.h5\n",
            "Epoch 2/100\n",
            "140/140 [==============================] - 88s 632ms/step - loss: 146.5225 - val_loss: 47.7174\n",
            "\n",
            "Epoch 00002: val_loss improved from 763.07068 to 47.71737, saving model to models/ep002-loss146.522-val_loss47.717.h5\n",
            "Epoch 3/100\n",
            "140/140 [==============================] - 89s 635ms/step - loss: 27.2169 - val_loss: 22.0856\n",
            "\n",
            "Epoch 00003: val_loss improved from 47.71737 to 22.08562, saving model to models/ep003-loss27.217-val_loss22.086.h5\n",
            "Epoch 4/100\n",
            "140/140 [==============================] - 88s 630ms/step - loss: 19.8132 - val_loss: 19.5975\n",
            "\n",
            "Epoch 00004: val_loss improved from 22.08562 to 19.59752, saving model to models/ep004-loss19.813-val_loss19.598.h5\n",
            "Epoch 5/100\n",
            "140/140 [==============================] - 89s 634ms/step - loss: 18.7160 - val_loss: 144.4563\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 19.59752\n",
            "Epoch 6/100\n",
            "140/140 [==============================] - 89s 638ms/step - loss: 17.1516 - val_loss: 16.4379\n",
            "\n",
            "Epoch 00006: val_loss improved from 19.59752 to 16.43785, saving model to models/ep006-loss17.152-val_loss16.438.h5\n",
            "Epoch 7/100\n",
            "140/140 [==============================] - 89s 633ms/step - loss: 16.0221 - val_loss: 25.4374\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 16.43785\n",
            "Epoch 8/100\n",
            "140/140 [==============================] - 88s 632ms/step - loss: 15.1881 - val_loss: 17.9394\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 16.43785\n",
            "Epoch 9/100\n",
            "140/140 [==============================] - 88s 632ms/step - loss: 14.4880 - val_loss: 15.4028\n",
            "\n",
            "Epoch 00009: val_loss improved from 16.43785 to 15.40282, saving model to models/ep009-loss14.488-val_loss15.403.h5\n",
            "Epoch 10/100\n",
            "140/140 [==============================] - 88s 630ms/step - loss: 13.8303 - val_loss: 13.6972\n",
            "\n",
            "Epoch 00010: val_loss improved from 15.40282 to 13.69719, saving model to models/ep010-loss13.830-val_loss13.697.h5\n",
            "Epoch 11/100\n",
            "140/140 [==============================] - 88s 630ms/step - loss: 13.1918 - val_loss: 16.2168\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 13.69719\n",
            "Epoch 12/100\n",
            "140/140 [==============================] - 88s 630ms/step - loss: 13.1235 - val_loss: 11.9320\n",
            "\n",
            "Epoch 00012: val_loss improved from 13.69719 to 11.93202, saving model to models/ep012-loss13.124-val_loss11.932.h5\n",
            "Epoch 13/100\n",
            "140/140 [==============================] - 89s 633ms/step - loss: 12.7179 - val_loss: 12.9741\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 11.93202\n",
            "Epoch 14/100\n",
            "140/140 [==============================] - 88s 632ms/step - loss: 12.4068 - val_loss: 13.4315\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 11.93202\n",
            "Epoch 15/100\n",
            "140/140 [==============================] - 88s 630ms/step - loss: 12.3176 - val_loss: 11.6114\n",
            "\n",
            "Epoch 00015: val_loss improved from 11.93202 to 11.61142, saving model to models/ep015-loss12.318-val_loss11.611.h5\n",
            "Epoch 16/100\n",
            "140/140 [==============================] - 88s 630ms/step - loss: 12.1153 - val_loss: 12.9591\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 11.61142\n",
            "Epoch 17/100\n",
            "140/140 [==============================] - 88s 631ms/step - loss: 11.8698 - val_loss: 11.8983\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 11.61142\n",
            "Epoch 18/100\n",
            "140/140 [==============================] - 88s 630ms/step - loss: 11.9107 - val_loss: 12.1530\n",
            "\n",
            "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.5.\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 11.61142\n",
            "Epoch 19/100\n",
            "140/140 [==============================] - 88s 631ms/step - loss: 11.1307 - val_loss: 11.6622\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 11.61142\n",
            "Epoch 20/100\n",
            "140/140 [==============================] - 88s 630ms/step - loss: 11.1523 - val_loss: 12.8886\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 11.61142\n",
            "Epoch 21/100\n",
            "117/140 [========================>.....] - ETA: 13s - loss: 11.0136Traceback (most recent call last):\n",
            "  File \"poly_yolo_lite.py\", line 1057, in <module>\n",
            "    _main()\n",
            "  File \"poly_yolo_lite.py\", line 985, in _main\n",
            "    callbacks=[reduce_lr, early_stopping, checkpoint])\n",
            "  File \"/tensorflow-1.15.2/python3.7/keras/legacy/interfaces.py\", line 91, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/tensorflow-1.15.2/python3.7/keras/engine/training.py\", line 1732, in fit_generator\n",
            "    initial_epoch=initial_epoch)\n",
            "  File \"/tensorflow-1.15.2/python3.7/keras/engine/training_generator.py\", line 220, in fit_generator\n",
            "    reset_metrics=False)\n",
            "  File \"/tensorflow-1.15.2/python3.7/keras/engine/training.py\", line 1514, in train_on_batch\n",
            "    outputs = self.train_function(ins)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/keras/backend.py\", line 3476, in __call__\n",
            "    run_metadata=self.run_metadata)\n",
            "  File \"/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\", line 1472, in __call__\n",
            "    run_metadata_ptr)\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data augmentation\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import imageio\n",
        "#import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from scipy import ndimage\n",
        "datagen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, \n",
        "height_shift_range=0.1,shear_range=0.15, zoom_range=0.1,channel_shift_range = 10, horizontal_flip=True)\n",
        "dir_imgs_name = '/content/poly-yolo/simulator_dataset/imgs'  #path_where_are_images_to_clasification\n",
        "# out_path = '/content/poly-yolo/poly_yolo_predict/' #path, where the images will be saved. The path must exist\n",
        "list_of_imgs = [root+\"/\"+name for root, dirs, files in os.walk(dir_imgs_name) for name in files]   \n",
        "list_of_imgs.sort()\n",
        "list_of_imgs = random.sample(list_of_imgs, 100)\n",
        "for dir in list_of_imgs:\n",
        "  image = np.expand_dims(imageio.imread(dir), 0)\n",
        "  datagen.fit(image)\n",
        "  for x in datagen.flow(image, save_to_dir=dir_imgs_name, save_prefix='img_aug', \n",
        "                            save_format='png', batch_size=10):\n",
        "    break\n",
        "\n"
      ],
      "metadata": {
        "id": "VDfw-BTH7XYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/poly-yolo/simulator_dataset/imgs')"
      ],
      "metadata": {
        "id": "avzYyNhilsdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import tensorflow as tf\n",
        "import imageio\n",
        "#import tensorflow_datasets as tfds\n",
        "from tensorflow.keras import layers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from scipy import ndimage\n",
        "datagen = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, \n",
        "height_shift_range=0.1,shear_range=0.15, zoom_range=0.1,channel_shift_range = 10, horizontal_flip=True)\n",
        "dir_imgs_name = '/content/poly-yolo/simulator_dataset/imgs'  #path_where_are_images_to_clasification\n",
        "# out_path = '/content/poly-yolo/poly_yolo_predict/' #path, where the images will be saved. The path must exist\n",
        "list_of_imgs = [root+\"/\"+name for root, dirs, files in os.walk(dir_imgs_name) for name in files]   \n",
        "list_of_imgs.sort()\n",
        "\n",
        "image = np.expand_dims(imageio.imread(list_of_imgs), 0)\n",
        "datagen.fit(image)\n",
        "\n",
        "for x in datagen.flow(image, save_to_dir=dir_imgs_name, save_prefix='img_aug', \n",
        "                            save_format='png', batch_size=10):\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "_snHq_fGTtmT",
        "outputId": "c113e81b-ccd2-4a6d-9151-c506cbaf9d23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-5f66fe860e83>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdir_imgs_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/poly-yolo/simulator_dataset/imgs'\u001b[0m  \u001b[0;31m#path_where_are_images_to_clasification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# out_path = '/content/poly-yolo/poly_yolo_predict/' #path, where the images will be saved. The path must exist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mlist_of_imgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_imgs_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mlist_of_imgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3_yYRqw8xEpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow --upgrade"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "O6cxxBdj_5VO",
        "outputId": "89b1eb11-49ab-4d68-8977-5cf856508839"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /tensorflow-1.15.2/python3.7 (1.15.2)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.8.0-cp37-cp37m-manylinux2010_x86_64.whl (497.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 497.5 MB 26 kB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Collecting keras<2.9,>=2.8.0rc0\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 58.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (13.0.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 73.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.24.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Collecting tensorboard<2.9,>=2.8\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 58.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Installing collected packages: tf-estimator-nightly, tensorboard, keras, tensorflow\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: Keras 2.3.1\n",
            "    Uninstalling Keras-2.3.1:\n",
            "      Successfully uninstalled Keras-2.3.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 1.15.2\n",
            "    Uninstalling tensorflow-1.15.2:\n",
            "      Successfully uninstalled tensorflow-1.15.2\n",
            "Successfully installed keras-2.8.0 tensorboard-2.8.0 tensorflow-2.8.0 tf-estimator-nightly-2.8.0.dev2021122109\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras",
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/519.v3i.yolokeras.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chNsVMSSgvld",
        "outputId": "840194f2-1548-4395-8f3b-e4aa018a7553"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open /content/519.v3i.yolokeras.zip, /content/519.v3i.yolokeras.zip.zip or /content/519.v3i.yolokeras.zip.ZIP.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = '/content/poly-yolo/poly_yolo/train'\n",
        "test_path = '/content/poly-yolo/poly_yolo/test'\n",
        "validation_path = '/content/poly-yolo/poly_yolo/valid'\n"
      ],
      "metadata": {
        "id": "LX5z9nPrl02U"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Copy_of_yolo_lighten.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}